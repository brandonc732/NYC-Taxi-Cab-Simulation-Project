{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f474898f-9f8a-4fca-bc82-43df81ae88d7",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook served as the **playground** for developing the simulation loops and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8484a9-0a13-4ec1-9728-43db9b760d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332ba89-6c11-41aa-ab4e-6d7f52244af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ee438-e4b0-4bb6-8ad9-ee2f499134b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d852bf-2298-4b9d-b5ab-ee4732b1edce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Develop Simulation setup\n",
    "## DONT FORGET TO MULTIPLY between euclidean distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7716c0ff-f95e-403e-9b84-06e5a5cc2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to convert 2D dataframe of numpy arrays to the following:\n",
    "- large 1D array of values\n",
    "- 2D array of bin starts within the 1D array\n",
    "- 2D array of bin lengths within the 1D array\n",
    "- If a cell entry is an empty array, then it will be replaced by one entry of np.inf (should only apply to inbetween variables)\n",
    "\n",
    "\"\"\"\n",
    "def convert_array_df(array_df):\n",
    "\n",
    "    #print(\"columns:\", array_df.columns)\n",
    "    #print(\"rows:\", array_df.index)\n",
    "\n",
    "    missing_cols = check_series_is_full(array_df.columns)\n",
    "    missing_rows = check_series_is_full(array_df.index)\n",
    "\n",
    "    if len(missing_rows) > 0 or len(missing_cols) > 0:\n",
    "        print(\"Filling in missing columns and rows with empty arrays\")\n",
    "        print(\"missing cols:\", missing_cols)\n",
    "        print(\"missing rows:\", missing_rows)\n",
    "\n",
    "        array_df = fill_df_missing_cols_rows(array_df)\n",
    "\n",
    "    num_rows, num_cols = array_df.shape\n",
    "\n",
    "    starts  = np.zeros((num_rows, num_cols), dtype=np.int64)\n",
    "    lengths = np.zeros((num_rows, num_cols), dtype=np.int64)\n",
    "\n",
    "    flat = []\n",
    "    \n",
    "    curr = 0\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "\n",
    "            arr = array_df.iat[i, j]\n",
    "\n",
    "            # if the array is empty, just replace it with np.inf array\n",
    "            if arr is None or len(arr) == 0:\n",
    "                arr = np.array([np.inf])\n",
    "\n",
    "            arr = np.asarray(arr)\n",
    "\n",
    "            starts[i, j] = curr\n",
    "            lengths[i, j]   = arr.size\n",
    "\n",
    "            flat.append(arr)\n",
    "            curr += arr.size\n",
    "\n",
    "    flat = np.concatenate(flat)\n",
    "\n",
    "    return {'values' : flat, 'starts' : starts, 'lengths' : lengths, \n",
    "            'min_row' : array_df.index.min(), 'min_col' : array_df.columns.min(),\n",
    "            'cols' : array_df.columns, 'rows' : array_df.index}\n",
    "\n",
    "\n",
    "def check_series_is_full(series):\n",
    "    missing = set(range(series.min(), series.max() + 1)) - set(series)\n",
    "    \n",
    "    return missing\n",
    "\n",
    "def fill_df_missing_cols_rows(df):\n",
    "    # create indexes for full range\n",
    "    full_index  = range(df.index.min(),   df.index.max()   + 1)\n",
    "    full_columns = range(df.columns.min(), df.columns.max() + 1)\n",
    "\n",
    "    # re-index to this complete index\n",
    "    df = df.reindex(index=full_index, columns=full_columns)\n",
    "    \n",
    "    # this created NaNs, which we can fill with empty arrays\n",
    "    df = df.map(lambda v: np.array([])    if     (v is None or (isinstance(v, float)     and np.isnan(v)))         else v)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe328fb-d521-4730-8e8c-8416d1f477e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to load information for sampling.\n",
    "\n",
    "This includes the following variables:\n",
    "\n",
    "- inbetween_miles_arrays:   (PU, DO)      #NEEDS MULTIPLICATION\n",
    "- inbetween_minutes_arrays: (PU, DO)\n",
    "\n",
    "- shift_durations: (hour,day)\n",
    "- shift_start_locations: (hour, day)\n",
    "\n",
    "- driver_count_arrays: (hour, day)\n",
    "- driver_count_deltas: (hour, day)\n",
    "\n",
    "\n",
    "To speed up sampling, each variable distribution will be given by:\n",
    "- large 1D array of values\n",
    "- 2D array of bin starts within the 1D array\n",
    "- 2D array of bin lengths within the 1D array\n",
    "- If a cell entry is an empty array, then it will be replaced by one entry of np.inf (should only apply to inbetween variables)\n",
    "\n",
    "NOTE: Everything is converted into seconds or miles\n",
    "\n",
    "\"\"\"\n",
    "def load_sampling_stuff():\n",
    "    import gc\n",
    "\n",
    "    print(\"Loading sampling info:\")\n",
    "    \n",
    "    print(\"Shift durations...\")\n",
    "    shift_durations = pd.read_pickle(\"data/sim_info/shift_arrays.pkl\")\n",
    "    shift_durations_info = convert_array_df(shift_durations)\n",
    "    del shift_durations\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Shift start locations...\")\n",
    "    shift_start_locations = pd.read_pickle(\"data/sim_info/shift_start_location_arrays.pkl\")\n",
    "    shift_start_locations_info = convert_array_df(shift_start_locations)\n",
    "    del shift_start_locations\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    print(\"driver counts...\")\n",
    "    driver_counts = pd.read_pickle(\"data/sim_info/driver_count_arrays.pkl\")\n",
    "    driver_counts_info = convert_array_df(driver_counts)\n",
    "    del driver_counts\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"driver count deltas...\")\n",
    "    driver_count_deltas = pd.read_pickle(\"data/sim_info/driver_delta_arrays.pkl\")\n",
    "    driver_count_deltas_info = convert_array_df(driver_count_deltas)\n",
    "    del driver_count_deltas\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    print(\"In between miles...\")\n",
    "    in_between_miles = pd.read_pickle(\"data/sim_info/in_between_miles_arrays.pkl\")\n",
    "    in_between_miles_info = convert_array_df(in_between_miles)\n",
    "    del in_between_miles\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"In between durations...\")\n",
    "    in_between_durations = pd.read_pickle(\"data/sim_info/in_between_minutes_arrays.pkl\")\n",
    "    in_between_durations_info = convert_array_df(in_between_durations)\n",
    "    del in_between_durations\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    print(\"Converting measurements\")\n",
    "\n",
    "    # convert times to seconds\n",
    "    shift_durations_info['values']      = shift_durations_info['values'] * 3600      # originally was hours\n",
    "    in_between_durations_info['values'] = in_between_durations_info['values'] * 60   # originally was minutes\n",
    "\n",
    "    # convert shift start locations to int16\n",
    "    shift_start_locations_info['values'] = shift_start_locations_info['values'].astype(np.int16)\n",
    "\n",
    "    # convert driver count stuff to int16\n",
    "    driver_counts_info['values'] = driver_counts_info['values'].astype(np.int16)\n",
    "    driver_count_deltas_info['values'] = driver_count_deltas_info['values'].astype(np.int16)\n",
    "\n",
    "    # apply LS equation from oak ridge paper to in between miles\n",
    "    in_between_miles_info['values'] = in_between_miles_info['values'] * 1.4413 + 0.1383\n",
    "\n",
    "\n",
    "    return {\n",
    "        'shift_durations'       : shift_durations_info,\n",
    "        'shift_start_locations' : shift_start_locations_info,\n",
    "        'in_between_miles'      : in_between_miles_info,\n",
    "        'in_between_durations'  : in_between_durations_info,\n",
    "        'driver_counts'         : driver_counts_info,\n",
    "        'driver_count_deltas'   : driver_count_deltas_info\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bb7ba-4cb9-4771-a56d-211c70fbcda3",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "## Get list of dropoff to pickup connections\n",
    "\n",
    "Create a list of what dropoff locations can service a pickup (index), not including the same location\n",
    "\n",
    "result: PU_to_DO[pickupID - 1] = list of dropoffID (taxi stops) that can service that pickup\n",
    "\n",
    "**NOTE**: sort them by the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26640a64-d930-4e89-8d66-c0be40fabe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PU_to_DO_connections(threshold):\n",
    "    in_between_df = pd.read_pickle(\"data/sim_info/in_between_minutes_arrays.pkl\")\n",
    "\n",
    "    #in_between_df.head()\n",
    "    \n",
    "    in_between_counts = in_between_df.map(len)\n",
    "    del in_between_df\n",
    "    \n",
    "    #in_between_counts.head()\n",
    "\n",
    "    # set any counts below the threshold to zero\n",
    "    counts_thresholded = in_between_counts.where(in_between_counts >= threshold, 0)\n",
    "    \n",
    "    #counts_thresholded.head()\n",
    "    \n",
    "    \n",
    "    # go through each pickup location and make a list of dropoff locations that can service them\n",
    "    PULocationIDs = counts_thresholded.index\n",
    "    \n",
    "    PU_DO_location_connectors= [[] for _ in range(PULocationIDs.min(), PULocationIDs.max()+1)]\n",
    "    \n",
    "    \n",
    "    for PU_location in PULocationIDs:\n",
    "    \n",
    "        # get the row of dropoff zones that can service the current pickup\n",
    "        connections_row = counts_thresholded.loc[PU_location]\n",
    "    \n",
    "        # sort the row entries by number of connections\n",
    "        connections_row = connections_row[connections_row > 0].sort_values(ascending=False)\n",
    "        \n",
    "        # get a list of columns above zero\n",
    "        DO_connections = connections_row.index.tolist()\n",
    "    \n",
    "        if PU_location in DO_connections:\n",
    "            DO_connections.remove(PU_location)\n",
    "        else:\n",
    "            #print(DO_location)\n",
    "            pass\n",
    "    \n",
    "        PU_DO_location_connectors[PU_location - PULocationIDs.min()] = DO_connections\n",
    "    \n",
    "    return {'data' : PU_DO_location_connectors,\n",
    "            'min_locationID' : PULocationIDs.min()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582df0e-b940-454d-a173-8ee6008338e0",
   "metadata": {},
   "source": [
    "## Simulation Constants\n",
    "\n",
    "- num 2013 taxis vs num 2023 taxis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "## Simulation variables\n",
    "- _range\n",
    "- car swap station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8401df5-2e99-449a-818b-21a1125e7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for simulating a NYC taxi driver\n",
    "\n",
    "attributes:\n",
    "\n",
    "\"\"\"\n",
    "class Taxi:\n",
    "    __slots__ = (\"_range\", \"_id\", \"LocationID\", \"shift_end\", \"time_available\")\n",
    "    def __init__(self, shift_start_time, shift_start_locationID, shift_duration, _range, _id):\n",
    "\n",
    "        self._range = _range\n",
    "        self._id = _id\n",
    "        \n",
    "        self.LocationID = shift_start_locationID\n",
    "        self.shift_end = shift_start_time + shift_duration\n",
    "\n",
    "        self.time_available = shift_start_time \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33129939-695a-4ab0-bb58-e7089a902110",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Simulation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba76f2d-2d8c-43f9-9964-e60585a6b7a1",
   "metadata": {},
   "source": [
    "### Initialize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3f7d35-3d90-45f9-b0d9-e8bcf0a88151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77df70ee-b3ea-4094-bbbd-867652fa48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sampling info:\n",
      "Shift durations...\n",
      "Shift start locations...\n",
      "driver counts...\n",
      "driver count deltas...\n",
      "In between miles...\n",
      "Filling in missing columns and rows with empty arrays\n",
      "missing cols: {104, 57, 105}\n",
      "missing rows: {104, 57, 105}\n",
      "In between durations...\n",
      "Filling in missing columns and rows with empty arrays\n",
      "missing cols: {104, 57, 105}\n",
      "missing rows: {104, 57, 105}\n",
      "Converting measurements\n"
     ]
    }
   ],
   "source": [
    "# load sampling distributions\n",
    "sampling_stuff = load_sampling_stuff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6acd84f1-e379-435b-8291-1aab33d564a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load information for DO to PU connections (filtered by occurance minimum threshold, default is 365)\n",
    "PU_to_DO_info = get_PU_to_DO_connections(threshold=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c370c3-593a-4702-8c08-d62ee83a66ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PU_time</th>\n",
       "      <th>PU_LocationID</th>\n",
       "      <th>DO_time</th>\n",
       "      <th>DO_LocationID</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>2023-01-01 00:00:05</td>\n",
       "      <td>249</td>\n",
       "      <td>2023-01-01 00:26:27</td>\n",
       "      <td>186</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2023-01-01 00:00:06</td>\n",
       "      <td>125</td>\n",
       "      <td>2023-01-01 00:05:44</td>\n",
       "      <td>68</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>2023-01-01 00:00:08</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-01-01 00:11:24</td>\n",
       "      <td>244</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>2023-01-01 00:00:09</td>\n",
       "      <td>79</td>\n",
       "      <td>2023-01-01 00:15:10</td>\n",
       "      <td>231</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>2023-01-01 00:00:13</td>\n",
       "      <td>132</td>\n",
       "      <td>2023-01-01 00:12:52</td>\n",
       "      <td>7</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PU_time  PU_LocationID             DO_time  DO_LocationID  \\\n",
       "3339 2023-01-01 00:00:05            249 2023-01-01 00:26:27            186   \n",
       "2412 2023-01-01 00:00:06            125 2023-01-01 00:05:44             68   \n",
       "3341 2023-01-01 00:00:08             42 2023-01-01 00:11:24            244   \n",
       "4277 2023-01-01 00:00:09             79 2023-01-01 00:15:10            231   \n",
       "3031 2023-01-01 00:00:13            132 2023-01-01 00:12:52              7   \n",
       "\n",
       "      distance  \n",
       "3339      1.32  \n",
       "2412      1.70  \n",
       "3341      3.10  \n",
       "4277      3.80  \n",
       "3031      8.97  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unformatted_trips = pd.read_parquet(\"data/sim_info/sim_trips_raw.parquet\")\n",
    "\n",
    "unformatted_trips = unformatted_trips.sort_values(by=\"PU_time\")\n",
    "\n",
    "unformatted_trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b3caf-7f2e-456b-9d8f-6c7aa74e5a12",
   "metadata": {},
   "source": [
    "### Convert trip times into seconds since start of 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ea6df7-3fd8-42c1-a4d6-1dff5f3c5f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PU_LocationID</th>\n",
       "      <th>DO_LocationID</th>\n",
       "      <th>distance</th>\n",
       "      <th>PU</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>186</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>68</td>\n",
       "      <td>1.70</td>\n",
       "      <td>6</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>244</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>231</td>\n",
       "      <td>3.80</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "      <td>8.97</td>\n",
       "      <td>13</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PU_LocationID  DO_LocationID  distance  PU  duration\n",
       "0            249            186      1.32   5      1582\n",
       "1            125             68      1.70   6       338\n",
       "2             42            244      3.10   8       676\n",
       "3             79            231      3.80   9       901\n",
       "4            132              7      8.97  13       759"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = pd.Timestamp(\"2023-01-01 00:00:00\")\n",
    "\n",
    "trips = unformatted_trips.copy()\n",
    "\n",
    "# Seconds since start of 2023\n",
    "trips['PU'] = (trips['PU_time'] - t0).dt.total_seconds().astype('int')\n",
    "\n",
    "trips['DO'] = (trips['DO_time'] - t0).dt.total_seconds().astype('int')\n",
    "\n",
    "trips.drop(columns=['PU_time', 'DO_time'], inplace=True)\n",
    "\n",
    "# create duration column in seconds and then drop dropoff time\n",
    "trips['duration'] = trips['DO'] - trips['PU']\n",
    "trips.drop(columns=['DO'], inplace=True)\n",
    "\n",
    "trips = trips.sort_values(by='PU')\n",
    "\n",
    "# reset trips index (used for flag to clean taxi cab array)\n",
    "trips = trips.reset_index()\n",
    "trips.drop(columns=['index'], inplace=True)\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d943dd-6e0a-44e5-902f-6b27f48dc971",
   "metadata": {},
   "source": [
    "### Import and convert shift times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93327031-3757-435f-8dd8-85bdaac277fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_df = pd.read_parquet('data/sim_info/shift_information.parquet')\n",
    "\n",
    "# convert start time to seconds from start of 2023\n",
    "shift_df['start_time'] = (shift_df['start_time']  - t0).dt.total_seconds().astype('int')\n",
    "\n",
    "# convert duration to seconds (is currently hours)\n",
    "shift_df['duration'] = (shift_df['duration'] * 3600).round().astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a91a1b5-6f37-4bc4-a4a3-5296bd576df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>start_locationID</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31532400</td>\n",
       "      <td>132</td>\n",
       "      <td>4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31532400</td>\n",
       "      <td>132</td>\n",
       "      <td>8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31532400</td>\n",
       "      <td>41</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31532400</td>\n",
       "      <td>138</td>\n",
       "      <td>5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31532400</td>\n",
       "      <td>132</td>\n",
       "      <td>41332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628391 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_time  start_locationID  duration\n",
       "53            0                65      1380\n",
       "58            0               138       141\n",
       "78            0                41       360\n",
       "80            0               226       360\n",
       "100           0               238      1440\n",
       "..          ...               ...       ...\n",
       "15     31532400               132      4440\n",
       "16     31532400               132      8884\n",
       "17     31532400                41      6300\n",
       "18     31532400               138      5460\n",
       "19     31532400               132     41332\n",
       "\n",
       "[2628391 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74ccf9-4fa4-47c3-bbd8-c5d8bdb87338",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "## Create taxi cab fleet class\n",
    "\n",
    "This class will have start with N taxi cab's\n",
    "\n",
    "They will be organized by location\n",
    "\n",
    "They will be spawned and choose a duration of the shift based on above sampling distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeca3c9b-98c2-40f9-ba84-83b2b955aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for managing the taxi cab fleet\n",
    "\n",
    "Will store active taxi cabs in an arry for each LocationID\n",
    "\"\"\"\n",
    "class TaxiFleet:\n",
    "\n",
    "    \"\"\"\n",
    "    Function to initialize taxi cab fleet\n",
    "\n",
    "    NOTE: all imputs are in seconds or miles\n",
    "\n",
    "    inputs:\n",
    "        - taxi_shifts_df\n",
    "        \n",
    "                A pandas dataframe of shift start times and start locationIDs. Should include columns: (start_time, start_locationID, and duration)\n",
    "\n",
    "                NOTE: everything should be based in seconds\n",
    "\n",
    "        - taxi_range\n",
    "\n",
    "                Number of range miles for a single taxi\n",
    "\n",
    "        - trips_df\n",
    "\n",
    "                dataframe of trips. Only used to get min and max locationIDs\n",
    "\n",
    "        - sampling_stuff\n",
    "\n",
    "                dictionary of sampling dictionaries with:\n",
    "                    - 'values'  : 1d array\n",
    "                    - 'starts'  : 2d array of start indexes within values\n",
    "                    - 'lengths' : 2d array of lengths for original cell arrays (num to sample from)\n",
    "                    - 'min_row' : minimum value of original df index (should be 1 for LocationIDs)\n",
    "                    - 'min_col' : minimum value of original df column\n",
    "                    - 'cols'    : column series of original dataframe\n",
    "                    - 'rows'    : rows seres of original dataframe\n",
    "\n",
    "        - PU_to_DO_info\n",
    "\n",
    "                keys:\n",
    "                    - 'data' list of lists with dropoff connectors to pickup i\n",
    "                    - 'min_locationID' original minimum location ID (should be 1)\n",
    "\n",
    "                \n",
    "    \"\"\"\n",
    "    def __init__(self, taxi_shifts_df, taxi_range, trips_df, sampling_stuff, PU_to_DO_info, low_range_threshold=30):\n",
    "\n",
    "        # store info for simulating taxis\n",
    "        self.taxi_range = taxi_range\n",
    "        self.low_range_threshold = low_range_threshold\n",
    "\n",
    "\n",
    "        self.setup_shift_info(taxi_shifts_df)\n",
    "\n",
    "        self.setup_cab_array(trips_df)\n",
    "\n",
    "        self.setup_sampling_info(sampling_stuff)\n",
    "\n",
    "        # save PU_to_DO list\n",
    "        self.PU_to_DO = PU_to_DO_info['data']\n",
    "        self.PU_to_DO_offset = PU_to_DO_info['min_locationID']\n",
    "\n",
    "\n",
    "        # logging stuff for debugging\n",
    "        self.cab_array_size_log = []\n",
    "\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "        # logging stuff for inference\n",
    "        self.taxi_rejections = []      # will be a list of dictionaries\n",
    "        self.taxi_below_threshold = [] # will be a list of dictionaries\n",
    "        \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Function to setup info for creating taxi drivers and shifts\n",
    "\n",
    "    input:\n",
    "        - taxis_shifts_df\n",
    "                pandas Dataframe with columns: 'start_seconds', 'start_locationID', 'shift_duration'\n",
    "    \"\"\"\n",
    "    def setup_shift_info(self, taxi_shifts_df : pd.DataFrame):\n",
    "        # store shifts dataframe for use in spawning taxis\n",
    "        #print(\"Sorting shift dataframe:\")\n",
    "        taxi_shifts_df = taxi_shifts_df.sort_values(by=\"start_time\")\n",
    "        self.shifts_df = taxi_shifts_df\n",
    "        \n",
    "        # create row indexer for taxi_shift_dataframe to keep track of the next shift to be added\n",
    "        self.next_shift_row = 0\n",
    "\n",
    "        # extract shift start_seconds, location ID, and shift duration seconds into numpy arrays for faster looking up\n",
    "        self.shift_start_times = self.shifts_df['start_time'].to_numpy()\n",
    "        self.shift_start_locations = self.shifts_df['start_locationID'].to_numpy()\n",
    "        self.shift_durations = self.shifts_df['duration'].to_numpy()\n",
    "\n",
    "        # append np.inf to the end of shift durations to make the final if condition always false (will never spawn taxi past that)\n",
    "        self.shift_start_times = np.append(self.shift_start_times, np.inf)\n",
    "\n",
    "    \"\"\"\n",
    "    Function to setup the empty cab lists and offset for indexing it\n",
    "    \"\"\"\n",
    "    def setup_cab_array(self, trips_df):\n",
    "\n",
    "        min_locationID = min(trips_df['PU_LocationID'].min(), trips_df['DO_LocationID'].min())\n",
    "        max_locationID = max(trips_df['PU_LocationID'].max(), trips_df['DO_LocationID'].max())\n",
    "\n",
    "        # create empty LocationID taxi cab arrays\n",
    "        self.cab_indexing_offset = min_locationID\n",
    "        self.cab_array = [[] for _ in range(min_locationID, max_locationID + 1)]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Function to setup stuff for sampling distributions\n",
    "\n",
    "    Each sampling info dictionary includes:\n",
    "        - 'values'  : 1d array\n",
    "        - 'starts'  : 2d array of start indexes within values\n",
    "        - 'lengths' : 2d array of lengths for original cell arrays (num to sample from)\n",
    "        - 'min_row' : minimum value of original df index (should be 1 for LocationIDs)\n",
    "        - 'min_col' : minimum value of original df column\n",
    "        - 'cols'    : column series of original dataframe\n",
    "        - 'rows'    : rows seres of original dataframe\n",
    "    \"\"\"\n",
    "    def setup_sampling_info(self, sampling_stuff):\n",
    "\n",
    "        # load in sampling stuff for in_between trips\n",
    "\n",
    "        # check that starts and lengths arrays are the same\n",
    "        assert np.array_equal(sampling_stuff['in_between_miles']['starts'], sampling_stuff['in_between_durations']['starts']), \"Error: sampling in_between miles and durations have mismatching starts arrays\"\n",
    "        assert np.array_equal(sampling_stuff['in_between_miles']['lengths'], sampling_stuff['in_between_durations']['lengths']), \"Error: sampling in_between miles and durations have mismatching lengths arrays\"\n",
    "        \n",
    "        # check that columns are dropoff and rows are pickup\n",
    "        assert sampling_stuff['in_between_durations']['cols'].name == \"DOLocationID\", \"Error: sampling in_between columns are not dropoff locations\"\n",
    "        assert sampling_stuff['in_between_durations']['rows'].name == \"PULocationID\", \"Error: sampling in_between columns are not pickup locations\"\n",
    "\n",
    "        # check that indexing offset is the same\n",
    "        assert sampling_stuff['in_between_miles']['min_col'] == sampling_stuff['in_between_miles']['min_row'] == sampling_stuff['in_between_durations']['min_col'] == sampling_stuff['in_between_durations']['min_row'], \"Error: sampling in_between miles and durations have mismatching min cols or rows\"\n",
    "\n",
    "        self.in_between_starts = sampling_stuff['in_between_miles']['starts']\n",
    "        self.in_between_lengths = sampling_stuff['in_between_miles']['lengths']\n",
    "        self.in_between_offset = sampling_stuff['in_between_miles']['min_col']\n",
    "\n",
    "        self.in_between_miles = sampling_stuff['in_between_miles']['values']\n",
    "        self.in_between_seconds = sampling_stuff['in_between_durations']['values']\n",
    "\n",
    "\n",
    "    def log_cab_array_size(self):\n",
    "        \n",
    "        curr_log = [len(taxi_list) for taxi_list in self.cab_array]\n",
    "        \n",
    "        self.cab_array_size_log.append(curr_log)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    function to remove all taxi cabs with end times past curr_time\n",
    "    \"\"\"\n",
    "    def clean_cab_array(self, curr_time):\n",
    "\n",
    "        #print(\"cleaning taxi array\")\n",
    "        for i, taxi_list in enumerate(self.cab_array):\n",
    "            if taxi_list:\n",
    "                taxi_list[:] = [t for t in taxi_list if t.shift_end >= curr_time]\n",
    "        #print(\"done\")\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Sample in between trip from starting location to ending location\n",
    "\n",
    "    based on sampling_stuff function, the columns=DOLocationID (startin_location), the rows=PULocationID(ending_location)\n",
    "    \"\"\"\n",
    "    def sample_in_between_trip(self, starting_location, ending_location):\n",
    "\n",
    "        ending_index, starting_idx = ending_location - self.in_between_offset, starting_location- self.in_between_offset\n",
    "        \n",
    "        start = self.in_between_starts[ending_index, starting_idx]\n",
    "        length = self.in_between_lengths[ending_index, starting_idx]\n",
    "\n",
    "        sample_index = self.rng.integers(length)\n",
    "        \n",
    "        miles = self.in_between_miles[start + sample_index]\n",
    "        seconds = self.in_between_seconds[start + sample_index]\n",
    "\n",
    "        return miles, seconds\n",
    "\n",
    "    \n",
    "\n",
    "    def check_spawn_taxi(self, curr_time_seconds):\n",
    "\n",
    "        # check that the row for the next shift is at or before curr_time\n",
    "        \"\"\"\n",
    "        while self.shift_start_times[self.next_shift_row] <= curr_time_seconds:\n",
    "\n",
    "            self.spawn_taxi(shift_index = self.next_shift_row)\n",
    "\n",
    "            self.next_shift_row += 1\n",
    "        \"\"\"\n",
    "        \n",
    "        # check that the row for the next shift is at or before curr_time\n",
    "        if self.shift_start_times[self.next_shift_row] <= curr_time_seconds:\n",
    "            \n",
    "            i = self.next_shift_row\n",
    "            j = np.searchsorted(self.shift_start_times, curr_time_seconds, side=\"right\")\n",
    "            \n",
    "            for idx in range(i,j):\n",
    "                self.spawn_taxi(shift_index = idx)\n",
    "\n",
    "            self.next_shift_row = j\n",
    "    \n",
    "\n",
    "    def spawn_taxi(self, shift_index):\n",
    "\n",
    "        # spawn a taxi based on the shift data at shift_index\n",
    "        new_taxi = Taxi(shift_start_time =       self.shift_start_times[shift_index], \n",
    "                        shift_start_locationID = self.shift_start_locations[shift_index], \n",
    "                        shift_duration =         self.shift_durations[shift_index], \n",
    "                        _range =                 self.taxi_range,\n",
    "                        _id = shift_index)\n",
    "\n",
    "        # add new taxi into corresponding locationID array\n",
    "        self.cab_array[new_taxi.LocationID - self.cab_indexing_offset].append(new_taxi)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that finds a taxi cab for a given trip\n",
    "\n",
    "    Starts by searching taxis in same pickup location area\n",
    "\n",
    "    moves to search taxis in other valid areas. These are determined by area pairs that meet a threshold for number of in_between samples from 2013 dataset\n",
    "\n",
    "\n",
    "    NOTE: This only samples distance once per dropoff location.\n",
    "    \n",
    "    I could consider implementing finding all matches then return cab with minimum distance in future\n",
    "\n",
    "\n",
    "    returns:\n",
    "        matched taxi object, index of its cab array (dropoffID), its index within that array\n",
    "    \"\"\"\n",
    "    def find_taxi_for_trip(self, pickup_time_seconds, pickup_location, distance):\n",
    "\n",
    "        # get cab list at pickup_location\n",
    "        taxi_list = self.cab_array[pickup_location - self.cab_indexing_offset]\n",
    "\n",
    "        # go through each cab within the same loction and check if valid\n",
    "        last_dropoff_location = pickup_location\n",
    "        ib_dist, ib_time = self.sample_in_between_trip(starting_location=last_dropoff_location,\n",
    "                                                         ending_location=pickup_location)\n",
    "\n",
    "        target_distance = distance + ib_dist\n",
    "        \n",
    "        for i in range(len(taxi_list)):\n",
    "            # check if time available is before pickup time\n",
    "            if taxi_list[i].time_available <= pickup_time_seconds:\n",
    "\n",
    "                # check if it's still on shift\n",
    "                if taxi_list[i].shift_end > pickup_time_seconds:\n",
    "                    \n",
    "                    # check if it has enough range\n",
    "                    if taxi_list[i]._range >= target_distance:\n",
    "                        return taxi_list[i], pickup_location, i, ib_dist, ib_time\n",
    "\n",
    "                    else:\n",
    "                        # log rejected taxi cause of range\n",
    "                        #print(\"Taxi skipped for no range\")\n",
    "                        self.taxi_rejections.append((pickup_time_seconds,      # requested pickup time\n",
    "                                                     taxi_list[i]._id,         # taxi id\n",
    "                                                     taxi_list[i].LocationID,  # current location\n",
    "                                                     taxi_list[i]._range,      # current range\n",
    "                                                     taxi_list[i].shift_end,   # taxi's shift end\n",
    "                                                     target_distance,          # requested distance\n",
    "                                                     pickup_location,          # pickup location\n",
    "                                                     distance,                 # trip distance\n",
    "                                                     ib_dist))                  # in-between distance\n",
    "                                                   \n",
    "\n",
    "        \n",
    "        # go through each cab within connecting locations and check if valid\n",
    "        # the location IDs should be sorted by number of connection instances in main dataset\n",
    "        connecting_DOs = self.PU_to_DO[pickup_location - self.PU_to_DO_offset]\n",
    "\n",
    "        for DO_location in connecting_DOs:\n",
    "            # get cab list at connecting dropoff \n",
    "            taxi_list = self.cab_array[DO_location - self.cab_indexing_offset]\n",
    "\n",
    "            ib_dist, ib_time = self.sample_in_between_trip(starting_location=DO_location,\n",
    "                                                           ending_location=pickup_location)\n",
    "            \n",
    "            target_distance = distance + ib_dist\n",
    "            \n",
    "            for i in range(len(taxi_list)):\n",
    "                # check if time available is before pickup time\n",
    "                if taxi_list[i].time_available <= pickup_time_seconds:\n",
    "    \n",
    "                    # check if it's still on shift\n",
    "                    if taxi_list[i].shift_end > pickup_time_seconds:\n",
    "                        \n",
    "                        # check if it has enough range\n",
    "                        if taxi_list[i]._range >= target_distance:\n",
    "                            return taxi_list[i], DO_location, i, ib_dist, ib_time\n",
    "    \n",
    "                        else:\n",
    "                            # log rejected taxi cause of range\n",
    "                            #print(\"Taxi skipped for no range\")\n",
    "                            self.taxi_rejections.append((pickup_time_seconds,      # requested pickup time\n",
    "                                                         taxi_list[i]._id,         # taxi id\n",
    "                                                         taxi_list[i].LocationID,  # current location\n",
    "                                                         taxi_list[i]._range,      # current range\n",
    "                                                         taxi_list[i].shift_end,   # taxi's shift end\n",
    "                                                         target_distance,          # requested distance\n",
    "                                                         pickup_location,          # pickup location\n",
    "                                                         distance,                 # trip distance\n",
    "                                                         ib_dist))                  # in-between distance\n",
    "\n",
    "        \n",
    "        return None, None, None, None, None # no taxi found\n",
    "\n",
    "                    \n",
    "        \n",
    "    \n",
    "    def assign_trip(self, pickup_time_seconds, pickup_location, duration, distance, dropoff_location):\n",
    "        # check if need to spawn more taxis\n",
    "        self.check_spawn_taxi(pickup_time_seconds)\n",
    "\n",
    "        \n",
    "        # find taxi for a trip\n",
    "        found = False\n",
    "        taxi, cab_list_location, taxi_array_index, ib_dist, ib_time = self.find_taxi_for_trip(pickup_time_seconds, pickup_location, distance)\n",
    "\n",
    "        # ib_dist and ib_time are the distance and time for the in_between trip\n",
    "        # this is when the taxi is driving from its last dropoff to the current pickup\n",
    "\n",
    "        # return false if no taxi is found\n",
    "        if taxi == None:\n",
    "            return False\n",
    "\n",
    "        # remove taxi from the cab list at it's location\n",
    "        # removed_cab = self.cab_array[cab_list_location - self.cab_indexing_offset].pop(taxi_array_index)\n",
    "        lst = self.cab_array[cab_list_location - self.cab_indexing_offset]\n",
    "        removed_cab = lst[taxi_array_index]\n",
    "        lst[taxi_array_index] = lst[-1]\n",
    "        lst.pop()\n",
    "        \n",
    "        # assign the taxi to the trip\n",
    "        taxi.LocationID = dropoff_location\n",
    "\n",
    "        # when a person is picked up, the taxi could have either already been on the way\n",
    "        # or the taxi could have just finished, so choose maximum time of the two scenarios\n",
    "        actual_pickup_time = max(pickup_time_seconds, taxi.time_available + ib_time)\n",
    "        \n",
    "        taxi.time_available = actual_pickup_time + duration\n",
    "        taxi._range -= (distance + ib_dist)\n",
    "\n",
    "        \n",
    "        # get remaining fuel at end of trip\n",
    "        # log if it's below a threshold (time, dropoff location ID, and remaining fuel)\n",
    "        if taxi._range <= self.low_range_threshold:\n",
    "            # log rejected taxi cause of range\n",
    "            #print(\"Taxi below range threshold\")\n",
    "            self.taxi_below_threshold.append((pickup_time_seconds, # current time\n",
    "                                              taxi._id,            # taxi id\n",
    "                                              taxi.LocationID,     # current location (after dropoff)\n",
    "                                              taxi._range,         # current range\n",
    "                                              taxi.shift_end,      # taxi's shift end\n",
    "                                              distance + ib_dist,  # distance just traveled\n",
    "                                              distance,            # trip distance just traveled\n",
    "                                              ib_dist))            # in-between distance just traveled\n",
    "\n",
    "\n",
    "        # delete the taxi cab if its next available time is past its shift\n",
    "        if taxi.time_available >= taxi.shift_end:\n",
    "            del taxi\n",
    "\n",
    "        else:\n",
    "            # otherwise, append it onto the taxi cab list at the dropoff location\n",
    "            self.cab_array[dropoff_location - self.cab_indexing_offset].append(taxi)\n",
    "\n",
    "        #self.log_cab_array_size()\n",
    "\n",
    "        # return True since trip was taken\n",
    "        return True\n",
    "\n",
    "# For doing back logged trips, we can just process them at the time of the next trip and just check if they match a taxi within a set time limit, and if they don't, we can remove them if the current time is also beyond the time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42901ab6-aeac-410b-9fd7-106b0f26877c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fed26c-5c78-4599-82b8-7aea7abddb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf78466e-1823-474f-b114-364c9ee1c932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Running the Simulation\n",
    "\n",
    "Initialize a TaxiFleet object and then run through all the trip rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70959fb-e752-4ca1-aaae-78da471b5f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdbc1c08-d91a-4dbd-bb9c-87624d75e2da",
   "metadata": {},
   "source": [
    "## Test one, run through all trips once. Track true and false, but no back logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996066b-5dc4-412f-bbca-852ca8294e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e37e6-ab3d-4a4e-baaf-1f123240da42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f122db-abc6-4498-9a73-36c95134cf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe367d7-0e83-4c0d-8054-80a088062323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87273f3-0aca-4338-9b77-3a90cd8da5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1e911-2849-464c-bb49-91aca9a4c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398985da-9a01-4338-9426-6392575f2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc503ff0-47e1-423e-bce8-f0b640c7b6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir('test_folders/test_1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc42d05-d45b-4ddb-b4bf-53d24d3554c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eef6c1-6927-4dec-bfdc-fbd2b0e7db5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b650b-e448-4e58-93c5-7e9dfa0dbbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdbbca-e84d-42f4-b10e-461c79223697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ee078-69f0-427f-b125-57a1108d5e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf97807-bf56-4665-9c04-4dee53adc171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5487d537-3e56-4fe1-b63f-2ae7ca95c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'test_folders/test_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e52715d-e200-4d78-b111-3e9d4e52ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(f\"{test_folder}/test_config.yaml\",'r') as f:\n",
    "    config_dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c90be1e3-8122-4c0e-9e8c-d9be5168f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "fleet = TaxiFleet(\n",
    "    taxi_shifts_df=shift_df, \n",
    "    taxi_range=config_dict['taxi_range'], \n",
    "    trips_df=trips, \n",
    "    sampling_stuff=sampling_stuff, \n",
    "    PU_to_DO_info=PU_to_DO_info,\n",
    "    low_range_threshold=config_dict['low_range_threshold']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bbf194b-e3e4-4ffb-b097-f051ac129054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–‹                                                                | 346198/35530878 [00:17<30:09, 19443.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m unfilled_trips \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(trips\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trips)):\n\u001b[1;32m---> 10\u001b[0m     taken \u001b[38;5;241m=\u001b[39m \u001b[43mfleet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_trip\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickup_time_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickup_location\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPU_LocationID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropoff_location\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDO_LocationID\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     takens\u001b[38;5;241m.\u001b[39mappend(taken)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mIndex \u001b[38;5;241m%\u001b[39m cab_array_cleaning_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m row\u001b[38;5;241m.\u001b[39mIndex \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m#before_size = np.array([len(taxi_array) for taxi_array in fleet.cab_array]).sum()\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m#print(\"before_size:\", before_size)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 329\u001b[0m, in \u001b[0;36mTaxiFleet.assign_trip\u001b[1;34m(self, pickup_time_seconds, pickup_location, duration, distance, dropoff_location)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# find taxi for a trip\u001b[39;00m\n\u001b[0;32m    328\u001b[0m found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m taxi, cab_list_location, taxi_array_index, ib_dist, ib_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_taxi_for_trip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickup_time_seconds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickup_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# ib_dist and ib_time are the distance and time for the in_between trip\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# this is when the taxi is driving from its last dropoff to the current pickup\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# return false if no taxi is found\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m taxi \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[13], line 287\u001b[0m, in \u001b[0;36mTaxiFleet.find_taxi_for_trip\u001b[1;34m(self, pickup_time_seconds, pickup_location, distance)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m DO_location \u001b[38;5;129;01min\u001b[39;00m connecting_DOs:\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# get cab list at connecting dropoff \u001b[39;00m\n\u001b[0;32m    285\u001b[0m     taxi_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcab_array[DO_location \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcab_indexing_offset]\n\u001b[1;32m--> 287\u001b[0m     ib_dist, ib_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_in_between_trip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarting_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDO_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mending_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickup_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     target_distance \u001b[38;5;241m=\u001b[39m distance \u001b[38;5;241m+\u001b[39m ib_dist\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(taxi_list)):\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;66;03m# check if time available is before pickup time\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run through all trips\n",
    "start = time.time()\n",
    "\n",
    "cab_array_cleaning_interval = config_dict['cab_array_cleaning_interval']\n",
    "\n",
    "takens = []\n",
    "unfilled_trips = []\n",
    "for row in tqdm(trips.itertuples(index=True), total=len(trips)):\n",
    "    \n",
    "    taken = fleet.assign_trip(\n",
    "        pickup_time_seconds = row.PU, \n",
    "        pickup_location     = row.PU_LocationID, \n",
    "        duration            = row.duration, \n",
    "        distance            = row.distance, \n",
    "        dropoff_location    = row.DO_LocationID\n",
    "    )\n",
    "\n",
    "    takens.append(taken)\n",
    "\n",
    "    if row.Index % cab_array_cleaning_interval == 0 and row.Index > 100:\n",
    "        #before_size = np.array([len(taxi_array) for taxi_array in fleet.cab_array]).sum()\n",
    "        #print(\"before_size:\", before_size)\n",
    "        fleet.clean_cab_array(curr_time=row.PU)\n",
    "        #after_size = np.array([len(taxi_array) for taxi_array in fleet.cab_array]).sum()\n",
    "        #print(\"after_size:\", after_size)\n",
    "        #break\n",
    "\n",
    "    if not taken:\n",
    "        unfilled_trips.append(row)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Simulation finished in {end - start} seconds.\")\n",
    "\n",
    "# convert data\n",
    "takens = np.array(takens)\n",
    "rejects_df = pd.DataFrame(fleet.taxi_rejections, columns=['request_time', 'id', 'location', 'range', 'shift_end', 'requested_distance', 'requested_location', 'requested_trip_distance', 'in_between_distance'])\n",
    "below_thresholds_df =  pd.DataFrame(fleet.taxi_below_threshold, columns=['request_time', 'id', 'location', 'range', 'shift_end', 'just_traveled', 'just_traveled_trip_distance', 'just_traveled_in_between_distance'])\n",
    "\n",
    "# revert request time and shift end back into date_times\n",
    "rejects_df['request_time'] = pd.to_datetime(rejects_df['request_time'], unit='s', origin='2023-01-01')\n",
    "rejects_df['shift_end'] = pd.to_datetime(rejects_df['shift_end'], unit='s', origin='2023-01-01')\n",
    "\n",
    "below_thresholds_df['request_time'] = pd.to_datetime(below_thresholds_df['request_time'], unit='s', origin='2023-01-01')\n",
    "below_thresholds_df['shift_end'] = pd.to_datetime(below_thresholds_df['shift_end'], unit='s', origin='2023-01-01')\n",
    "\n",
    "\n",
    "# save information\n",
    "print(\"Saving info...\")\n",
    "rejects_df.to_parquet(rejects_export_path)\n",
    "below_thresholds_df.to_parquet(below_thresholds_export_path)\n",
    "\n",
    "print(\"done\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# print takens stats\n",
    "print(\"number of non filled rides:\", (takens == 0).sum())\n",
    "print(\"percentage:\", takens.mean())\n",
    "\n",
    "\n",
    "# write to save file\n",
    "with open(sim_time_export, \"w\") as f:\n",
    "    f.write(f\"Simulation finished in {end - start} seconds.\\n\")\n",
    "    f.write(f\"number of non filled rides: {(takens == 0).sum()}\\n\")\n",
    "    f.write(f\"percentage: {takens.mean()}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81be544-a1c9-454e-b74a-fc0dd43f4f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63efc1-4813-4934-bc51-20caa83d4c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f14586-5b29-4193-9308-b02aa3e357e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af912cc9-d4fb-44d1-8d4a-dbdf3f60b741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4918b77-6230-4d73-a381-9d2b68b609d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a238eb-7781-4227-9d92-87e76c7a1f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7465a52-122a-407d-bb75-9db322bdf61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48eff72-39b0-4ee1-af24-c363cf01d4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a257674-fa5d-43cf-aafe-6f5818f171e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78347dd-3a8a-4c07-85f3-b8103f12bb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217725d1-8c64-4f7e-9015-1e9f09bce852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1b224-98ee-4e40-92bc-bd4a66420909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc617c-ce3e-4ec3-a0d5-a9f3f018cc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96403725-bc11-4840-bc1f-6b4975977cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8ce31-4c77-4244-b0eb-0a06f755b306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc0469-c362-47ed-8784-4491c9f6f0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6757baf-3fa1-4722-9e7d-d06fa432ed1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb1785-357f-4e57-a213-56cc536a479a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa1785-21d2-4c60-be5a-81b764769a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce627f01-6ac0-486c-8bbc-9659620e26d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6607f-6c13-48f2-893d-e0c2eb820c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffe666-3ba0-45ba-8148-643c4617110d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391ade3-416c-44d4-a680-6e9fcfc5cc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a1892-5db8-4560-a5a9-c2569ce8ecc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc681f93-8a75-49f5-bc8e-e40e70f8237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59c16f4-5166-4820-90b4-c825aa49c1ec",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "# Generate shift starts dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33469c0-1712-4f72-9d3e-e1c901107443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28af46-1cc7-4622-8e82-4de6306d369f",
   "metadata": {},
   "source": [
    "#### Data imports\n",
    "\n",
    "All of the following dataframes are indexed by:\n",
    "- row = hour (0-23)\n",
    "- column = day of week (0-6) Monday=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce7c365-a072-4a6a-9ee8-d8a11bd78a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift start counts...\n",
      "Shift durations...\n",
      "Shift start locations...\n",
      "driver counts...\n"
     ]
    }
   ],
   "source": [
    "print(\"Shift start counts...\")\n",
    "shift_counts_df = pd.read_pickle(\"data/sim_info/shift_start_counts_arrays.pkl\")\n",
    "\n",
    "print(\"Shift durations...\")\n",
    "shift_durations_df = pd.read_pickle(\"data/sim_info/shift_arrays.pkl\")\n",
    "\n",
    "print(\"Shift start locations...\")\n",
    "shift_start_locationsIDs_df = pd.read_pickle(\"data/sim_info/shift_start_location_arrays.pkl\")\n",
    "\n",
    "print(\"driver counts...\")\n",
    "driver_count_df = pd.read_pickle(\"data/sim_info/driver_count_arrays.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc7094-f85f-482b-bd54-ede6d121495a",
   "metadata": {},
   "source": [
    "## Remove any extreme values from shift start counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dda7dc4-c1e2-49db-ae3d-43a8a1aeaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(arr, k=3.0):\n",
    "    \"\"\"\n",
    "    Remove extreme outliers from a 1D numpy array using the IQR rule.\n",
    "    Returns a new array with only non-outlier values.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return arr  # keep empty arrays as-is\n",
    "\n",
    "    # Use percentiles for robustness\n",
    "    q1, q3 = np.percentile(arr, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0:\n",
    "        # All values nearly identical; nothing to remove\n",
    "        return arr\n",
    "\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "\n",
    "    mask = (arr >= lower) & (arr <= upper)\n",
    "\n",
    "    removed = arr[~mask]\n",
    "    if len(removed) > 0:\n",
    "        #print(\"Removed:\", removed)\n",
    "        #print(\"Kepted:\", arr[mask])\n",
    "        #print(\"\\n\\n\")\n",
    "        pass\n",
    "    return arr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c954b4-fa16-49fa-988b-b802bfe790ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shift_counts_df = shift_counts_df.map(remove_outliers_iqr)\n",
    "\n",
    "driver_count_df = driver_count_df.map(remove_outliers_iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b97b7f-cdc9-419c-9547-f275fe60508b",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "## Scale down driver and occurence counts based on the ratio between 2013 unique drivers and 2023 unique drivers\n",
    "\n",
    "- 2013 unique drivers: 33,300\n",
    "- 2023 unique drivers: 11,700\n",
    "\n",
    "https://toddwschneider.com/dashboards/nyc-taxi-ridehailing-uber-lyft-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c6b68a-57c4-4531-ba59-5e7bdb6c59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_levels_2013 = 33_300\n",
    "driver_levels_2023 = 11_700\n",
    "\n",
    "extra_reducer = 0.5\n",
    "\n",
    "reduction = extra_reducer * (driver_levels_2023 / driver_levels_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f031426-7007-4ce5-8f45-261ae73cdc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_counts_df = shift_counts_df.map(lambda arr: np.rint(arr * reduction).astype(np.int16))\n",
    "\n",
    "driver_count_df = driver_count_df.map(lambda arr: np.rint(arr * reduction).astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4945b7e0-4631-44f5-a763-1a9a627f3565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>day</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[717, 792, 1010, 766, 993, 854, 1057, 955, 857...</td>\n",
       "      <td>[902, 958, 786, 870, 887, 1046, 874, 949, 1020...</td>\n",
       "      <td>[1003, 1185, 1114, 1123, 1122, 1313, 1082, 125...</td>\n",
       "      <td>[1144, 1257, 1161, 1304, 1339, 1400, 1285, 132...</td>\n",
       "      <td>[1450, 1502, 1502, 1630, 1640, 1654, 1583, 163...</td>\n",
       "      <td>[1701, 1746, 1829, 1731, 1860, 1832, 1851, 187...</td>\n",
       "      <td>[1713, 1809, 1799, 1836, 1804, 1683, 1801, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[486, 584, 791, 483, 562, 540, 814, 587, 528, ...</td>\n",
       "      <td>[594, 595, 490, 557, 534, 685, 526, 575, 605, ...</td>\n",
       "      <td>[659, 750, 657, 702, 677, 845, 658, 794, 733, ...</td>\n",
       "      <td>[617, 760, 811, 726, 853, 849, 926, 814, 849, ...</td>\n",
       "      <td>[1037, 1079, 1040, 1165, 1224, 1266, 1140, 118...</td>\n",
       "      <td>[1541, 1596, 1690, 1580, 1738, 1701, 1745, 176...</td>\n",
       "      <td>[1607, 1716, 1698, 1751, 1712, 1601, 1728, 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[326, 364, 587, 330, 374, 355, 356, 350, 371, ...</td>\n",
       "      <td>[393, 393, 309, 359, 345, 408, 322, 369, 393, ...</td>\n",
       "      <td>[285, 420, 473, 403, 453, 419, 544, 424, 476, ...</td>\n",
       "      <td>[403, 500, 536, 461, 542, 545, 588, 516, 562, ...</td>\n",
       "      <td>[541, 710, 746, 696, 787, 852, 888, 767, 813, ...</td>\n",
       "      <td>[1296, 1409, 1481, 1382, 1540, 1507, 1540, 158...</td>\n",
       "      <td>[1445, 1575, 1556, 1615, 1568, 1462, 1584, 157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[244, 263, 248, 275, 262, 254, 264, 281, 304, ...</td>\n",
       "      <td>[282, 277, 227, 247, 241, 298, 238, 261, 266, ...</td>\n",
       "      <td>[210, 321, 346, 285, 314, 307, 376, 300, 327, ...</td>\n",
       "      <td>[287, 348, 368, 305, 367, 370, 397, 349, 386, ...</td>\n",
       "      <td>[389, 491, 523, 482, 539, 606, 615, 538, 575, ...</td>\n",
       "      <td>[1028, 1125, 1212, 1106, 1268, 1240, 1267, 131...</td>\n",
       "      <td>[1213, 1364, 1334, 1380, 1332, 1259, 1359, 136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[268, 288, 374, 281, 292, 279, 386, 285, 303, ...</td>\n",
       "      <td>[259, 263, 244, 247, 252, 282, 255, 269, 288, ...</td>\n",
       "      <td>[296, 323, 287, 297, 281, 345, 287, 318, 318, ...</td>\n",
       "      <td>[290, 321, 343, 293, 324, 341, 371, 336, 355, ...</td>\n",
       "      <td>[339, 415, 442, 413, 435, 519, 487, 442, 482, ...</td>\n",
       "      <td>[736, 782, 882, 771, 898, 888, 905, 933, 881, ...</td>\n",
       "      <td>[859, 1006, 994, 1004, 938, 920, 1008, 996, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[452, 460, 367, 468, 472, 492, 373, 475, 487, ...</td>\n",
       "      <td>[420, 442, 442, 440, 434, 466, 476, 439, 455, ...</td>\n",
       "      <td>[426, 435, 459, 464, 431, 446, 467, 471, 468, ...</td>\n",
       "      <td>[441, 463, 487, 441, 477, 484, 509, 486, 495, ...</td>\n",
       "      <td>[429, 483, 533, 503, 517, 564, 526, 507, 534, ...</td>\n",
       "      <td>[415, 436, 516, 450, 509, 497, 510, 525, 501, ...</td>\n",
       "      <td>[449, 496, 501, 528, 473, 499, 534, 528, 547, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[850, 883, 902, 901, 923, 939, 963, 878, 912, ...</td>\n",
       "      <td>[882, 900, 952, 940, 940, 956, 954, 986, 976, ...</td>\n",
       "      <td>[809, 895, 910, 973, 934, 942, 977, 980, 969, ...</td>\n",
       "      <td>[838, 922, 946, 892, 951, 984, 996, 998, 985, ...</td>\n",
       "      <td>[825, 918, 965, 947, 970, 981, 967, 997, 1028,...</td>\n",
       "      <td>[456, 458, 539, 481, 526, 558, 550, 574, 562, ...</td>\n",
       "      <td>[424, 437, 447, 484, 432, 486, 485, 495, 507, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1292, 1301, 1341, 1350, 1362, 1379, 1398, 133...</td>\n",
       "      <td>[1364, 1415, 1464, 1430, 1430, 1477, 1424, 145...</td>\n",
       "      <td>[1193, 1398, 1383, 1463, 1463, 1440, 1455, 146...</td>\n",
       "      <td>[1305, 1439, 1452, 1342, 1385, 1518, 1485, 148...</td>\n",
       "      <td>[1293, 1412, 1452, 1459, 1461, 1432, 1460, 150...</td>\n",
       "      <td>[631, 658, 701, 676, 715, 710, 737, 742, 775, ...</td>\n",
       "      <td>[529, 561, 535, 619, 547, 585, 548, 602, 616, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1522, 1562, 1559, 1566, 1569, 1602, 1589, 155...</td>\n",
       "      <td>[1614, 1668, 1707, 1655, 1686, 1698, 1641, 170...</td>\n",
       "      <td>[1477, 1638, 1603, 1697, 1655, 1660, 1636, 168...</td>\n",
       "      <td>[1587, 1668, 1680, 1563, 1615, 1719, 1673, 169...</td>\n",
       "      <td>[1544, 1645, 1657, 1688, 1658, 1656, 1672, 170...</td>\n",
       "      <td>[842, 896, 955, 932, 989, 994, 1014, 1046, 105...</td>\n",
       "      <td>[717, 734, 709, 789, 746, 785, 725, 857, 815, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1600, 1641, 1657, 1646, 1680, 1669, 1665, 167...</td>\n",
       "      <td>[1691, 1776, 1792, 1749, 1780, 1791, 1749, 179...</td>\n",
       "      <td>[1561, 1714, 1680, 1788, 1718, 1748, 1719, 177...</td>\n",
       "      <td>[1684, 1751, 1742, 1620, 1687, 1786, 1740, 178...</td>\n",
       "      <td>[1615, 1712, 1727, 1784, 1728, 1735, 1732, 175...</td>\n",
       "      <td>[1093, 1142, 1179, 1155, 1219, 1211, 1260, 127...</td>\n",
       "      <td>[888, 951, 919, 1000, 955, 1027, 956, 1057, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1525, 1594, 1635, 1607, 1679, 1647, 1643, 165...</td>\n",
       "      <td>[1663, 1741, 1765, 1698, 1762, 1782, 1707, 177...</td>\n",
       "      <td>[1549, 1657, 1681, 1774, 1670, 1728, 1726, 174...</td>\n",
       "      <td>[1627, 1730, 1712, 1622, 1683, 1785, 1727, 177...</td>\n",
       "      <td>[1587, 1686, 1716, 1766, 1733, 1746, 1736, 175...</td>\n",
       "      <td>[1291, 1324, 1374, 1339, 1389, 1408, 1449, 145...</td>\n",
       "      <td>[1128, 1187, 1163, 1227, 1194, 1272, 1209, 130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1464, 1546, 1319, 1584, 1582, 1658, 1376, 156...</td>\n",
       "      <td>[1594, 1674, 1720, 1655, 1692, 1753, 1645, 169...</td>\n",
       "      <td>[1480, 1615, 1671, 1751, 1678, 1711, 1674, 171...</td>\n",
       "      <td>[1605, 1667, 1673, 1613, 1663, 1744, 1704, 175...</td>\n",
       "      <td>[1567, 1628, 1691, 1726, 1697, 1701, 1707, 174...</td>\n",
       "      <td>[1426, 1427, 1484, 1487, 1502, 1501, 1570, 155...</td>\n",
       "      <td>[1287, 1379, 1313, 1366, 1330, 1410, 1365, 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1468, 1514, 1331, 1600, 1575, 1596, 1426, 153...</td>\n",
       "      <td>[1590, 1653, 1697, 1656, 1686, 1714, 1659, 167...</td>\n",
       "      <td>[1626, 1682, 1747, 1663, 1747, 1701, 1723, 172...</td>\n",
       "      <td>[1579, 1688, 1696, 1595, 1654, 1736, 1709, 175...</td>\n",
       "      <td>[1465, 1529, 1587, 1591, 1587, 1580, 1558, 160...</td>\n",
       "      <td>[1472, 1494, 1531, 1518, 1568, 1542, 1603, 161...</td>\n",
       "      <td>[1372, 1460, 1390, 1443, 1410, 1488, 1450, 148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1483, 1556, 1411, 1609, 1560, 1581, 1473, 156...</td>\n",
       "      <td>[1600, 1678, 1707, 1678, 1683, 1712, 1712, 168...</td>\n",
       "      <td>[1555, 1654, 1664, 1739, 1669, 1731, 1702, 173...</td>\n",
       "      <td>[1625, 1684, 1705, 1595, 1662, 1738, 1710, 177...</td>\n",
       "      <td>[1517, 1595, 1573, 1621, 1609, 1602, 1616, 162...</td>\n",
       "      <td>[1564, 1573, 1567, 1616, 1623, 1603, 1668, 168...</td>\n",
       "      <td>[1447, 1518, 1470, 1510, 1473, 1509, 1525, 154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1553, 1612, 1484, 1650, 1594, 1626, 1518, 162...</td>\n",
       "      <td>[1652, 1690, 1737, 1693, 1731, 1737, 1712, 171...</td>\n",
       "      <td>[1594, 1665, 1681, 1775, 1664, 1760, 1726, 176...</td>\n",
       "      <td>[1644, 1710, 1725, 1601, 1702, 1775, 1724, 177...</td>\n",
       "      <td>[1623, 1701, 1656, 1728, 1700, 1574, 1675, 171...</td>\n",
       "      <td>[1581, 1595, 1601, 1628, 1646, 1607, 1699, 169...</td>\n",
       "      <td>[1501, 1557, 1534, 1562, 1541, 1560, 1553, 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1501, 1588, 1496, 1622, 1587, 1568, 1486, 154...</td>\n",
       "      <td>[1562, 1638, 1700, 1616, 1628, 1633, 1609, 163...</td>\n",
       "      <td>[1541, 1588, 1606, 1714, 1604, 1647, 1615, 168...</td>\n",
       "      <td>[1556, 1627, 1643, 1624, 1637, 1643, 1576, 164...</td>\n",
       "      <td>[1559, 1618, 1615, 1668, 1637, 1392, 1571, 162...</td>\n",
       "      <td>[1540, 1596, 1540, 1597, 1612, 1548, 1628, 163...</td>\n",
       "      <td>[1466, 1542, 1511, 1543, 1530, 1564, 1530, 154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1362, 1446, 1438, 1479, 1507, 1436, 1407, 142...</td>\n",
       "      <td>[1379, 1445, 1529, 1429, 1468, 1465, 1450, 147...</td>\n",
       "      <td>[1378, 1402, 1444, 1536, 1396, 1485, 1457, 150...</td>\n",
       "      <td>[1424, 1450, 1446, 1493, 1462, 1485, 1411, 148...</td>\n",
       "      <td>[1428, 1422, 1462, 1515, 1513, 1419, 1491, 148...</td>\n",
       "      <td>[1421, 1457, 1442, 1468, 1487, 1303, 1431, 148...</td>\n",
       "      <td>[1386, 1465, 1428, 1430, 1446, 1493, 1424, 143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1520, 1588, 1467, 1611, 1632, 1579, 1476, 158...</td>\n",
       "      <td>[1540, 1571, 1648, 1570, 1617, 1553, 1594, 160...</td>\n",
       "      <td>[1497, 1544, 1600, 1630, 1553, 1631, 1566, 160...</td>\n",
       "      <td>[1542, 1588, 1631, 1642, 1566, 1580, 1548, 158...</td>\n",
       "      <td>[1542, 1484, 1618, 1611, 1629, 1580, 1629, 164...</td>\n",
       "      <td>[1525, 1549, 1531, 1478, 1519, 1472, 1502, 150...</td>\n",
       "      <td>[1392, 1479, 1426, 1401, 1475, 1506, 1434, 143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1707, 1770, 1591, 1792, 1807, 1818, 1611, 179...</td>\n",
       "      <td>[1757, 1799, 1868, 1767, 1851, 1806, 1809, 185...</td>\n",
       "      <td>[1705, 1789, 1822, 1854, 1786, 1861, 1803, 185...</td>\n",
       "      <td>[1737, 1841, 1836, 1857, 1800, 1813, 1802, 184...</td>\n",
       "      <td>[1777, 1730, 1831, 1784, 1854, 1806, 1863, 188...</td>\n",
       "      <td>[1720, 1718, 1736, 1701, 1759, 1648, 1736, 171...</td>\n",
       "      <td>[1464, 1512, 1502, 1526, 1518, 1624, 1561, 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1701, 1759, 1520, 1772, 1821, 1846, 1624, 179...</td>\n",
       "      <td>[1799, 1845, 1900, 1868, 1872, 1896, 1858, 190...</td>\n",
       "      <td>[1716, 1808, 1880, 1906, 1871, 1930, 1878, 191...</td>\n",
       "      <td>[1788, 1925, 1899, 1946, 1893, 1925, 1898, 194...</td>\n",
       "      <td>[1844, 1874, 1908, 1854, 1909, 1876, 1940, 196...</td>\n",
       "      <td>[1777, 1805, 1799, 1820, 1845, 1735, 1815, 179...</td>\n",
       "      <td>[1375, 1386, 1495, 1504, 1378, 1577, 1559, 151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1636, 1677, 1464, 1695, 1753, 1769, 1520, 172...</td>\n",
       "      <td>[1763, 1828, 1867, 1842, 1843, 1907, 1796, 188...</td>\n",
       "      <td>[1610, 1798, 1861, 1882, 1837, 1916, 1875, 190...</td>\n",
       "      <td>[1764, 1918, 1932, 1970, 1957, 1953, 1932, 194...</td>\n",
       "      <td>[1873, 1936, 1940, 1870, 1959, 1906, 1955, 198...</td>\n",
       "      <td>[1781, 1828, 1823, 1868, 1884, 1754, 1840, 182...</td>\n",
       "      <td>[1303, 1272, 1389, 1422, 1195, 1468, 1497, 141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1526, 1639, 1396, 1591, 1633, 1656, 1442, 163...</td>\n",
       "      <td>[1721, 1771, 1793, 1783, 1780, 1857, 1689, 182...</td>\n",
       "      <td>[1751, 1806, 1807, 1775, 1857, 1847, 1864, 183...</td>\n",
       "      <td>[1712, 1857, 1906, 1913, 1929, 1936, 1919, 191...</td>\n",
       "      <td>[1814, 1892, 1903, 1841, 1958, 1899, 1922, 197...</td>\n",
       "      <td>[1712, 1783, 1778, 1861, 1854, 1741, 1837, 181...</td>\n",
       "      <td>[1225, 1239, 1329, 1328, 1192, 1360, 1456, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1433, 1557, 1303, 1489, 1548, 1573, 1358, 154...</td>\n",
       "      <td>[1607, 1713, 1732, 1696, 1685, 1772, 1658, 176...</td>\n",
       "      <td>[1681, 1773, 1712, 1758, 1807, 1816, 1810, 180...</td>\n",
       "      <td>[1820, 1849, 1849, 1898, 1909, 1906, 1871, 188...</td>\n",
       "      <td>[1802, 1848, 1918, 1825, 1934, 1920, 1911, 194...</td>\n",
       "      <td>[1784, 1821, 1813, 1884, 1864, 1759, 1859, 186...</td>\n",
       "      <td>[1091, 1180, 1309, 1231, 1211, 1271, 1391, 124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1256, 1343, 1112, 1267, 1248, 1379, 1177, 131...</td>\n",
       "      <td>[1384, 1567, 1524, 1533, 1491, 1640, 1481, 160...</td>\n",
       "      <td>[1489, 1617, 1574, 1609, 1670, 1729, 1659, 166...</td>\n",
       "      <td>[1710, 1741, 1751, 1836, 1803, 1827, 1795, 179...</td>\n",
       "      <td>[1771, 1802, 1880, 1795, 1904, 1903, 1896, 189...</td>\n",
       "      <td>[1781, 1838, 1831, 1877, 1847, 1732, 1862, 185...</td>\n",
       "      <td>[962, 1042, 1211, 1055, 1233, 1112, 1247, 1061...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "day                                                   0  \\\n",
       "hour                                                      \n",
       "0     [717, 792, 1010, 766, 993, 854, 1057, 955, 857...   \n",
       "1     [486, 584, 791, 483, 562, 540, 814, 587, 528, ...   \n",
       "2     [326, 364, 587, 330, 374, 355, 356, 350, 371, ...   \n",
       "3     [244, 263, 248, 275, 262, 254, 264, 281, 304, ...   \n",
       "4     [268, 288, 374, 281, 292, 279, 386, 285, 303, ...   \n",
       "5     [452, 460, 367, 468, 472, 492, 373, 475, 487, ...   \n",
       "6     [850, 883, 902, 901, 923, 939, 963, 878, 912, ...   \n",
       "7     [1292, 1301, 1341, 1350, 1362, 1379, 1398, 133...   \n",
       "8     [1522, 1562, 1559, 1566, 1569, 1602, 1589, 155...   \n",
       "9     [1600, 1641, 1657, 1646, 1680, 1669, 1665, 167...   \n",
       "10    [1525, 1594, 1635, 1607, 1679, 1647, 1643, 165...   \n",
       "11    [1464, 1546, 1319, 1584, 1582, 1658, 1376, 156...   \n",
       "12    [1468, 1514, 1331, 1600, 1575, 1596, 1426, 153...   \n",
       "13    [1483, 1556, 1411, 1609, 1560, 1581, 1473, 156...   \n",
       "14    [1553, 1612, 1484, 1650, 1594, 1626, 1518, 162...   \n",
       "15    [1501, 1588, 1496, 1622, 1587, 1568, 1486, 154...   \n",
       "16    [1362, 1446, 1438, 1479, 1507, 1436, 1407, 142...   \n",
       "17    [1520, 1588, 1467, 1611, 1632, 1579, 1476, 158...   \n",
       "18    [1707, 1770, 1591, 1792, 1807, 1818, 1611, 179...   \n",
       "19    [1701, 1759, 1520, 1772, 1821, 1846, 1624, 179...   \n",
       "20    [1636, 1677, 1464, 1695, 1753, 1769, 1520, 172...   \n",
       "21    [1526, 1639, 1396, 1591, 1633, 1656, 1442, 163...   \n",
       "22    [1433, 1557, 1303, 1489, 1548, 1573, 1358, 154...   \n",
       "23    [1256, 1343, 1112, 1267, 1248, 1379, 1177, 131...   \n",
       "\n",
       "day                                                   1  \\\n",
       "hour                                                      \n",
       "0     [902, 958, 786, 870, 887, 1046, 874, 949, 1020...   \n",
       "1     [594, 595, 490, 557, 534, 685, 526, 575, 605, ...   \n",
       "2     [393, 393, 309, 359, 345, 408, 322, 369, 393, ...   \n",
       "3     [282, 277, 227, 247, 241, 298, 238, 261, 266, ...   \n",
       "4     [259, 263, 244, 247, 252, 282, 255, 269, 288, ...   \n",
       "5     [420, 442, 442, 440, 434, 466, 476, 439, 455, ...   \n",
       "6     [882, 900, 952, 940, 940, 956, 954, 986, 976, ...   \n",
       "7     [1364, 1415, 1464, 1430, 1430, 1477, 1424, 145...   \n",
       "8     [1614, 1668, 1707, 1655, 1686, 1698, 1641, 170...   \n",
       "9     [1691, 1776, 1792, 1749, 1780, 1791, 1749, 179...   \n",
       "10    [1663, 1741, 1765, 1698, 1762, 1782, 1707, 177...   \n",
       "11    [1594, 1674, 1720, 1655, 1692, 1753, 1645, 169...   \n",
       "12    [1590, 1653, 1697, 1656, 1686, 1714, 1659, 167...   \n",
       "13    [1600, 1678, 1707, 1678, 1683, 1712, 1712, 168...   \n",
       "14    [1652, 1690, 1737, 1693, 1731, 1737, 1712, 171...   \n",
       "15    [1562, 1638, 1700, 1616, 1628, 1633, 1609, 163...   \n",
       "16    [1379, 1445, 1529, 1429, 1468, 1465, 1450, 147...   \n",
       "17    [1540, 1571, 1648, 1570, 1617, 1553, 1594, 160...   \n",
       "18    [1757, 1799, 1868, 1767, 1851, 1806, 1809, 185...   \n",
       "19    [1799, 1845, 1900, 1868, 1872, 1896, 1858, 190...   \n",
       "20    [1763, 1828, 1867, 1842, 1843, 1907, 1796, 188...   \n",
       "21    [1721, 1771, 1793, 1783, 1780, 1857, 1689, 182...   \n",
       "22    [1607, 1713, 1732, 1696, 1685, 1772, 1658, 176...   \n",
       "23    [1384, 1567, 1524, 1533, 1491, 1640, 1481, 160...   \n",
       "\n",
       "day                                                   2  \\\n",
       "hour                                                      \n",
       "0     [1003, 1185, 1114, 1123, 1122, 1313, 1082, 125...   \n",
       "1     [659, 750, 657, 702, 677, 845, 658, 794, 733, ...   \n",
       "2     [285, 420, 473, 403, 453, 419, 544, 424, 476, ...   \n",
       "3     [210, 321, 346, 285, 314, 307, 376, 300, 327, ...   \n",
       "4     [296, 323, 287, 297, 281, 345, 287, 318, 318, ...   \n",
       "5     [426, 435, 459, 464, 431, 446, 467, 471, 468, ...   \n",
       "6     [809, 895, 910, 973, 934, 942, 977, 980, 969, ...   \n",
       "7     [1193, 1398, 1383, 1463, 1463, 1440, 1455, 146...   \n",
       "8     [1477, 1638, 1603, 1697, 1655, 1660, 1636, 168...   \n",
       "9     [1561, 1714, 1680, 1788, 1718, 1748, 1719, 177...   \n",
       "10    [1549, 1657, 1681, 1774, 1670, 1728, 1726, 174...   \n",
       "11    [1480, 1615, 1671, 1751, 1678, 1711, 1674, 171...   \n",
       "12    [1626, 1682, 1747, 1663, 1747, 1701, 1723, 172...   \n",
       "13    [1555, 1654, 1664, 1739, 1669, 1731, 1702, 173...   \n",
       "14    [1594, 1665, 1681, 1775, 1664, 1760, 1726, 176...   \n",
       "15    [1541, 1588, 1606, 1714, 1604, 1647, 1615, 168...   \n",
       "16    [1378, 1402, 1444, 1536, 1396, 1485, 1457, 150...   \n",
       "17    [1497, 1544, 1600, 1630, 1553, 1631, 1566, 160...   \n",
       "18    [1705, 1789, 1822, 1854, 1786, 1861, 1803, 185...   \n",
       "19    [1716, 1808, 1880, 1906, 1871, 1930, 1878, 191...   \n",
       "20    [1610, 1798, 1861, 1882, 1837, 1916, 1875, 190...   \n",
       "21    [1751, 1806, 1807, 1775, 1857, 1847, 1864, 183...   \n",
       "22    [1681, 1773, 1712, 1758, 1807, 1816, 1810, 180...   \n",
       "23    [1489, 1617, 1574, 1609, 1670, 1729, 1659, 166...   \n",
       "\n",
       "day                                                   3  \\\n",
       "hour                                                      \n",
       "0     [1144, 1257, 1161, 1304, 1339, 1400, 1285, 132...   \n",
       "1     [617, 760, 811, 726, 853, 849, 926, 814, 849, ...   \n",
       "2     [403, 500, 536, 461, 542, 545, 588, 516, 562, ...   \n",
       "3     [287, 348, 368, 305, 367, 370, 397, 349, 386, ...   \n",
       "4     [290, 321, 343, 293, 324, 341, 371, 336, 355, ...   \n",
       "5     [441, 463, 487, 441, 477, 484, 509, 486, 495, ...   \n",
       "6     [838, 922, 946, 892, 951, 984, 996, 998, 985, ...   \n",
       "7     [1305, 1439, 1452, 1342, 1385, 1518, 1485, 148...   \n",
       "8     [1587, 1668, 1680, 1563, 1615, 1719, 1673, 169...   \n",
       "9     [1684, 1751, 1742, 1620, 1687, 1786, 1740, 178...   \n",
       "10    [1627, 1730, 1712, 1622, 1683, 1785, 1727, 177...   \n",
       "11    [1605, 1667, 1673, 1613, 1663, 1744, 1704, 175...   \n",
       "12    [1579, 1688, 1696, 1595, 1654, 1736, 1709, 175...   \n",
       "13    [1625, 1684, 1705, 1595, 1662, 1738, 1710, 177...   \n",
       "14    [1644, 1710, 1725, 1601, 1702, 1775, 1724, 177...   \n",
       "15    [1556, 1627, 1643, 1624, 1637, 1643, 1576, 164...   \n",
       "16    [1424, 1450, 1446, 1493, 1462, 1485, 1411, 148...   \n",
       "17    [1542, 1588, 1631, 1642, 1566, 1580, 1548, 158...   \n",
       "18    [1737, 1841, 1836, 1857, 1800, 1813, 1802, 184...   \n",
       "19    [1788, 1925, 1899, 1946, 1893, 1925, 1898, 194...   \n",
       "20    [1764, 1918, 1932, 1970, 1957, 1953, 1932, 194...   \n",
       "21    [1712, 1857, 1906, 1913, 1929, 1936, 1919, 191...   \n",
       "22    [1820, 1849, 1849, 1898, 1909, 1906, 1871, 188...   \n",
       "23    [1710, 1741, 1751, 1836, 1803, 1827, 1795, 179...   \n",
       "\n",
       "day                                                   4  \\\n",
       "hour                                                      \n",
       "0     [1450, 1502, 1502, 1630, 1640, 1654, 1583, 163...   \n",
       "1     [1037, 1079, 1040, 1165, 1224, 1266, 1140, 118...   \n",
       "2     [541, 710, 746, 696, 787, 852, 888, 767, 813, ...   \n",
       "3     [389, 491, 523, 482, 539, 606, 615, 538, 575, ...   \n",
       "4     [339, 415, 442, 413, 435, 519, 487, 442, 482, ...   \n",
       "5     [429, 483, 533, 503, 517, 564, 526, 507, 534, ...   \n",
       "6     [825, 918, 965, 947, 970, 981, 967, 997, 1028,...   \n",
       "7     [1293, 1412, 1452, 1459, 1461, 1432, 1460, 150...   \n",
       "8     [1544, 1645, 1657, 1688, 1658, 1656, 1672, 170...   \n",
       "9     [1615, 1712, 1727, 1784, 1728, 1735, 1732, 175...   \n",
       "10    [1587, 1686, 1716, 1766, 1733, 1746, 1736, 175...   \n",
       "11    [1567, 1628, 1691, 1726, 1697, 1701, 1707, 174...   \n",
       "12    [1465, 1529, 1587, 1591, 1587, 1580, 1558, 160...   \n",
       "13    [1517, 1595, 1573, 1621, 1609, 1602, 1616, 162...   \n",
       "14    [1623, 1701, 1656, 1728, 1700, 1574, 1675, 171...   \n",
       "15    [1559, 1618, 1615, 1668, 1637, 1392, 1571, 162...   \n",
       "16    [1428, 1422, 1462, 1515, 1513, 1419, 1491, 148...   \n",
       "17    [1542, 1484, 1618, 1611, 1629, 1580, 1629, 164...   \n",
       "18    [1777, 1730, 1831, 1784, 1854, 1806, 1863, 188...   \n",
       "19    [1844, 1874, 1908, 1854, 1909, 1876, 1940, 196...   \n",
       "20    [1873, 1936, 1940, 1870, 1959, 1906, 1955, 198...   \n",
       "21    [1814, 1892, 1903, 1841, 1958, 1899, 1922, 197...   \n",
       "22    [1802, 1848, 1918, 1825, 1934, 1920, 1911, 194...   \n",
       "23    [1771, 1802, 1880, 1795, 1904, 1903, 1896, 189...   \n",
       "\n",
       "day                                                   5  \\\n",
       "hour                                                      \n",
       "0     [1701, 1746, 1829, 1731, 1860, 1832, 1851, 187...   \n",
       "1     [1541, 1596, 1690, 1580, 1738, 1701, 1745, 176...   \n",
       "2     [1296, 1409, 1481, 1382, 1540, 1507, 1540, 158...   \n",
       "3     [1028, 1125, 1212, 1106, 1268, 1240, 1267, 131...   \n",
       "4     [736, 782, 882, 771, 898, 888, 905, 933, 881, ...   \n",
       "5     [415, 436, 516, 450, 509, 497, 510, 525, 501, ...   \n",
       "6     [456, 458, 539, 481, 526, 558, 550, 574, 562, ...   \n",
       "7     [631, 658, 701, 676, 715, 710, 737, 742, 775, ...   \n",
       "8     [842, 896, 955, 932, 989, 994, 1014, 1046, 105...   \n",
       "9     [1093, 1142, 1179, 1155, 1219, 1211, 1260, 127...   \n",
       "10    [1291, 1324, 1374, 1339, 1389, 1408, 1449, 145...   \n",
       "11    [1426, 1427, 1484, 1487, 1502, 1501, 1570, 155...   \n",
       "12    [1472, 1494, 1531, 1518, 1568, 1542, 1603, 161...   \n",
       "13    [1564, 1573, 1567, 1616, 1623, 1603, 1668, 168...   \n",
       "14    [1581, 1595, 1601, 1628, 1646, 1607, 1699, 169...   \n",
       "15    [1540, 1596, 1540, 1597, 1612, 1548, 1628, 163...   \n",
       "16    [1421, 1457, 1442, 1468, 1487, 1303, 1431, 148...   \n",
       "17    [1525, 1549, 1531, 1478, 1519, 1472, 1502, 150...   \n",
       "18    [1720, 1718, 1736, 1701, 1759, 1648, 1736, 171...   \n",
       "19    [1777, 1805, 1799, 1820, 1845, 1735, 1815, 179...   \n",
       "20    [1781, 1828, 1823, 1868, 1884, 1754, 1840, 182...   \n",
       "21    [1712, 1783, 1778, 1861, 1854, 1741, 1837, 181...   \n",
       "22    [1784, 1821, 1813, 1884, 1864, 1759, 1859, 186...   \n",
       "23    [1781, 1838, 1831, 1877, 1847, 1732, 1862, 185...   \n",
       "\n",
       "day                                                   6  \n",
       "hour                                                     \n",
       "0     [1713, 1809, 1799, 1836, 1804, 1683, 1801, 182...  \n",
       "1     [1607, 1716, 1698, 1751, 1712, 1601, 1728, 172...  \n",
       "2     [1445, 1575, 1556, 1615, 1568, 1462, 1584, 157...  \n",
       "3     [1213, 1364, 1334, 1380, 1332, 1259, 1359, 136...  \n",
       "4     [859, 1006, 994, 1004, 938, 920, 1008, 996, 10...  \n",
       "5     [449, 496, 501, 528, 473, 499, 534, 528, 547, ...  \n",
       "6     [424, 437, 447, 484, 432, 486, 485, 495, 507, ...  \n",
       "7     [529, 561, 535, 619, 547, 585, 548, 602, 616, ...  \n",
       "8     [717, 734, 709, 789, 746, 785, 725, 857, 815, ...  \n",
       "9     [888, 951, 919, 1000, 955, 1027, 956, 1057, 10...  \n",
       "10    [1128, 1187, 1163, 1227, 1194, 1272, 1209, 130...  \n",
       "11    [1287, 1379, 1313, 1366, 1330, 1410, 1365, 142...  \n",
       "12    [1372, 1460, 1390, 1443, 1410, 1488, 1450, 148...  \n",
       "13    [1447, 1518, 1470, 1510, 1473, 1509, 1525, 154...  \n",
       "14    [1501, 1557, 1534, 1562, 1541, 1560, 1553, 155...  \n",
       "15    [1466, 1542, 1511, 1543, 1530, 1564, 1530, 154...  \n",
       "16    [1386, 1465, 1428, 1430, 1446, 1493, 1424, 143...  \n",
       "17    [1392, 1479, 1426, 1401, 1475, 1506, 1434, 143...  \n",
       "18    [1464, 1512, 1502, 1526, 1518, 1624, 1561, 155...  \n",
       "19    [1375, 1386, 1495, 1504, 1378, 1577, 1559, 151...  \n",
       "20    [1303, 1272, 1389, 1422, 1195, 1468, 1497, 141...  \n",
       "21    [1225, 1239, 1329, 1328, 1192, 1360, 1456, 129...  \n",
       "22    [1091, 1180, 1309, 1231, 1211, 1271, 1391, 124...  \n",
       "23    [962, 1042, 1211, 1055, 1233, 1112, 1247, 1061...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683eeb28-0b2b-4108-b38a-70a63c346d1e",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "## Create dataframes of driver count array means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74056373-af04-48ba-806b-c4607bbde275",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_count_means = driver_count_df.map(np.mean)\n",
    "driver_count_stds = driver_count_df.map(np.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b470b5f-d897-4576-86de-cb8afda7d1b5",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "### Overview\n",
    "\n",
    "generate shifts dataframe from a couple days before and a couple days after.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d22a2b-70c8-4c9f-9b4b-813f0cb93089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c95963e-e247-44b9-b408-19c93d49983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9073/9073 [00:21<00:00, 430.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# start a couple days before 2023\n",
    "start_time = pd.Timestamp('2022-12-20')\n",
    "adjustment_start = start_time + pd.Timedelta(days=5)\n",
    "\n",
    "# z_scores to add to remove shifts at\n",
    "low_z_threshold = -3\n",
    "high_z_threshold = 3\n",
    "\n",
    "\n",
    "# end a couple days after 2023\n",
    "timestamp_end = pd.Timestamp('2024-01-02')\n",
    "#timestamp_end = pd.Timestamp('2023-01-02')\n",
    "\n",
    "shifts_dataframe = pd.DataFrame(columns=['start_time', 'start_locationID', 'duration', 'end_time'])\n",
    "\n",
    "\n",
    "z_scores_list = []\n",
    "z_adjustment_messages = []\n",
    "\n",
    "hours = pd.date_range(start=start_time, end=timestamp_end, freq=\"h\")\n",
    "n = len(hours)\n",
    "\n",
    "\n",
    "# make this long enough for max duration you might see (pick a safe buffer)\n",
    "end_counts = np.zeros(n + 72*2, dtype=np.int32)  # e.g. +144 hours buffer\n",
    "current_active = 0\n",
    "\n",
    "chunks = []\n",
    "meta = []\n",
    "\n",
    "for t_idx, curr_time in tqdm(enumerate(hours), total=len(hours)):\n",
    "\n",
    "    current_active -= end_counts[t_idx]\n",
    "\n",
    "    # get hour and day of week for current time\n",
    "    hour = curr_time.hour\n",
    "    dow  = curr_time.day_of_week\n",
    "\n",
    "    # sample the number of shifts to generate\n",
    "    num_starts = np.random.choice(shift_counts_df[dow][hour])\n",
    "\n",
    "    # sample data arrays for these shifts\n",
    "    new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=num_starts)\n",
    "    new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=num_starts)\n",
    "\n",
    "    # create new shifts\n",
    "    new_shifts = []\n",
    "    new_end_buckets = []\n",
    "    for i in range(num_starts):\n",
    "        # sample a new shift\n",
    "        # I'm just going to start shifts on the hour\n",
    "        new_shift_location_ID = new_location_IDs[i]\n",
    "        new_shift_duration = new_durations[i]\n",
    "        new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "\n",
    "        end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "        end_counts[end_bucket] += 1\n",
    "        new_end_buckets.append(end_bucket)\n",
    "\n",
    "        new_shifts.append({\n",
    "            'start_time' : curr_time,\n",
    "            'start_locationID' : new_shift_location_ID,\n",
    "            'duration' : new_shift_duration,\n",
    "            'end_time' : new_shift_end\n",
    "        })\n",
    "\n",
    "    # create new shift dataframe\n",
    "    new_shift_df = pd.DataFrame(new_shifts)\n",
    "\n",
    "    \n",
    "    current_active += num_starts\n",
    "\n",
    "    chunks.append(new_shift_df)\n",
    "    meta.append(np.array(new_end_buckets))\n",
    "\n",
    "    \n",
    "    # append onto overall dataframe\n",
    "    #shifts_dataframe = pd.concat([shifts_dataframe, new_shift_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    # get the number of active drivers by how many rows have end_time > curr_time\n",
    "    #current_active = (shifts_dataframe.iloc[-15_000:]['end_time'] > curr_time).sum()\n",
    "\n",
    "\n",
    "    # Since the driver_count_df didn't have any outliers when doing the iqr filtering,\n",
    "    # I'm going to use standard z-score for outlier detection for generation driver counts\n",
    "    obs_mean = driver_count_means[dow][hour]\n",
    "    obs_std  = driver_count_stds[dow][hour]\n",
    "    z_score = (current_active - obs_mean) / obs_std\n",
    "\n",
    "    if z_score > high_z_threshold and curr_time > adjustment_start: # there's too many drivers\n",
    "\n",
    "        # remove drivers to bring back into range\n",
    "        desired_amount = obs_mean + high_z_threshold * obs_std\n",
    "\n",
    "        amount_to_remove = int(current_active - desired_amount)\n",
    "\n",
    "        log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to remove: {amount_to_remove}\"\n",
    "        #print(log_message)\n",
    "        z_adjustment_messages.append(log_message)\n",
    "\n",
    "        # remove the rows from bottom of dataframe\n",
    "        # shifts_dataframe = shifts_dataframe.iloc[:-amount_to_remove]\n",
    "\n",
    "        k = amount_to_remove\n",
    "        while k > 0 and chunks:\n",
    "            last_df = chunks[-1]\n",
    "            last_buckets = meta[-1]\n",
    "            take = min(k, len(last_df))\n",
    "\n",
    "            # undo those shifts in the end_counts + active count\n",
    "            np.add.at(end_counts, last_buckets[-take:], -1)\n",
    "            current_active -= take\n",
    "\n",
    "            # trim/pop chunk\n",
    "            if take == len(last_df):\n",
    "                chunks.pop(); meta.pop()\n",
    "            else:\n",
    "                chunks[-1] = last_df.iloc[:-take]\n",
    "                meta[-1] = last_buckets[:-take]\n",
    "            k -= take\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    if z_score < low_z_threshold and curr_time > adjustment_start: # theres too little drivers\n",
    "\n",
    "        # remove drivers to bring back into range\n",
    "        desired_amount = obs_mean + low_z_threshold * obs_std\n",
    "\n",
    "        amount_to_add = int(desired_amount - current_active)\n",
    "\n",
    "        log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to add: {amount_to_add}\"\n",
    "        #print(log_message)\n",
    "        z_adjustment_messages.append(log_message)\n",
    "\n",
    "        \n",
    "        # create that many drivers\n",
    "        new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=amount_to_add)\n",
    "        new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=amount_to_add)\n",
    "\n",
    "        # create new shifts\n",
    "        new_shifts = []\n",
    "        new_end_buckets = []\n",
    "        for i in range(amount_to_add):\n",
    "            # sample a new shift\n",
    "            # I'm just going to start shifts on the hour\n",
    "            new_shift_location_ID = new_location_IDs[i]\n",
    "            new_shift_duration = new_durations[i]\n",
    "            new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "    \n",
    "            end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "            end_counts[end_bucket] += 1\n",
    "            new_end_buckets.append(end_bucket)\n",
    "    \n",
    "            new_shifts.append({\n",
    "                'start_time' : curr_time,\n",
    "                'start_locationID' : new_shift_location_ID,\n",
    "                'duration' : new_shift_duration,\n",
    "                'end_time' : new_shift_end\n",
    "            })\n",
    "    \n",
    "        # create new shift dataframe\n",
    "        new_shift_df = pd.DataFrame(new_shifts)\n",
    "    \n",
    "        \n",
    "        current_active += amount_to_add\n",
    "    \n",
    "        chunks[-1] = pd.concat([chunks[-1], new_shift_df], ignore_index=True)\n",
    "        meta[-1] = np.concat((meta[-1], np.array(new_end_buckets)))\n",
    "\n",
    "\n",
    "    z_scores_list.append(z_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f7c6bd-e0b1-4e66-9181-a1fc0e62f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_dataframe = pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0ee8fe-3d5f-4cbf-a81d-b117b24e8bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_scores = np.array(z_scores_list)\n",
    "\n",
    "z_scores = z_scores[24*5:]\n",
    "\n",
    "plt.plot(z_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950fbc58-9e1f-4354-b018-873c64424551",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "## Slice and format the shift dataframe then save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbfe857-e02e-4260-8f1c-fcf68d1e5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out anything that starts in 2024\n",
    "sliced_shifts = shift_dataframe[shift_dataframe['start_time'] < pd.Timestamp('2024-01-01')]\n",
    "\n",
    "# slice out anything that ends before 2023\n",
    "sliced_shifts = sliced_shifts[sliced_shifts['end_time'] >= pd.Timestamp('2023-01-01')]\n",
    "\n",
    "# clamp start times to begging of 2023 and recalculate duration based on end_time\n",
    "cutoff = pd.Timestamp('2023-01-01 00:00:00')\n",
    "mask = sliced_shifts['start_time'] < cutoff\n",
    "\n",
    "# Update duration for affected rows (in hours)\n",
    "sliced_shifts.loc[mask, 'duration'] = (\n",
    "    sliced_shifts.loc[mask, 'end_time'] - cutoff\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Clamp start_time to cutoff\n",
    "sliced_shifts.loc[mask, 'start_time'] = cutoff\n",
    "\n",
    "\n",
    "# set location ID column to int16\n",
    "sliced_shifts['start_locationID'] = sliced_shifts['start_locationID'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b360a3-d3e9-47c0-9a94-d36042783dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>start_locationID</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>141</td>\n",
       "      <td>0.726111</td>\n",
       "      <td>2023-01-01 00:43:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2023-01-01 00:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>238</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2023-01-01 00:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>226</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>2023-01-01 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2023-01-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>132</td>\n",
       "      <td>11.753889</td>\n",
       "      <td>2024-01-01 10:45:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>5.170278</td>\n",
       "      <td>2024-01-01 04:10:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>2024-01-01 00:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>164</td>\n",
       "      <td>7.266667</td>\n",
       "      <td>2024-01-01 06:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2024-01-01 00:44:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314928 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             start_time  start_locationID   duration            end_time\n",
       "72  2023-01-01 00:00:00               141   0.726111 2023-01-01 00:43:34\n",
       "100 2023-01-01 00:00:00               138   0.866667 2023-01-01 00:52:00\n",
       "128 2023-01-01 00:00:00               238   0.733333 2023-01-01 00:44:00\n",
       "130 2023-01-01 00:00:00               226   0.016667 2023-01-01 00:01:00\n",
       "137 2023-01-01 00:00:00                65   0.750000 2023-01-01 00:45:00\n",
       "..                  ...               ...        ...                 ...\n",
       "2   2023-12-31 23:00:00               132  11.753889 2024-01-01 10:45:14\n",
       "3   2023-12-31 23:00:00               138   5.170278 2024-01-01 04:10:13\n",
       "4   2023-12-31 23:00:00               138   1.916667 2024-01-01 00:55:00\n",
       "5   2023-12-31 23:00:00               164   7.266667 2024-01-01 06:16:00\n",
       "6   2023-12-31 23:00:00               138   1.733333 2024-01-01 00:44:00\n",
       "\n",
       "[1314928 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06c3ea3-7e94-4fed-a155-65c167db326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove end_time (not required for simulation)\n",
    "export_shifts = sliced_shifts.drop(columns=['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "071044cc-ce38-49ba-831d-be7a63dbbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_shifts.to_parquet('shift_information.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29d16f-70a4-4a23-a00f-e178923e0995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c30cbc-9f63-4568-bae4-1136e6ac6eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3953af7-f14a-4d62-a3d4-2796e1a196ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b80b1c-8b7c-43b3-b7c3-9b40db545e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244db685-d4d7-4273-bf75-87543a7b06a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46846ce-9f58-4611-941a-5841f1898482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126a01b3-ec9d-470b-9dbf-b155042e8de7",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "# Automate generating shift information for 2023 simulations (scaled from 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfba722-c5de-4b6e-9322-1d330ea37dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd66450-25f4-41cf-b562-938e88748a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(arr, k=3.0):\n",
    "    \"\"\"\n",
    "    Remove extreme outliers from a 1D numpy array using the IQR rule.\n",
    "    Returns a new array with only non-outlier values.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return arr  # keep empty arrays as-is\n",
    "\n",
    "    # Use percentiles for robustness\n",
    "    q1, q3 = np.percentile(arr, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0:\n",
    "        # All values nearly identical; nothing to remove\n",
    "        return arr\n",
    "\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "\n",
    "    mask = (arr >= lower) & (arr <= upper)\n",
    "\n",
    "    removed = arr[~mask]\n",
    "    if len(removed) > 0:\n",
    "        #print(\"Removed:\", removed)\n",
    "        #print(\"Kepted:\", arr[mask])\n",
    "        #print(\"\\n\\n\")\n",
    "        pass\n",
    "    return arr[mask]\n",
    "\n",
    "\n",
    "def generate_shifts_dataframe(driver_levels_2013 = 33_300, driver_levels_2023 = 11_700, extra_reducer=0.7):\n",
    "\n",
    "    # load data\n",
    "    print(\"Shift start counts...\")\n",
    "    shift_counts_df = pd.read_pickle(\"data/sim_info/shift_start_counts_arrays.pkl\")\n",
    "    \n",
    "    print(\"Shift durations...\")\n",
    "    shift_durations_df = pd.read_pickle(\"data/sim_info/shift_arrays.pkl\")\n",
    "    \n",
    "    print(\"Shift start locations...\")\n",
    "    shift_start_locationsIDs_df = pd.read_pickle(\"data/sim_info/shift_start_location_arrays.pkl\")\n",
    "    \n",
    "    print(\"driver counts...\")\n",
    "    driver_count_df = pd.read_pickle(\"data/sim_info/driver_count_arrays.pkl\")\n",
    "\n",
    "\n",
    "    # filter extreme outliers in count dataframes\n",
    "    shift_counts_df = shift_counts_df.map(remove_outliers_iqr)\n",
    "    driver_count_df = driver_count_df.map(remove_outliers_iqr)\n",
    "\n",
    "\n",
    "\n",
    "    # scale the count levels from 2013 to 2023 with extra reducer for shift hours and stuff\n",
    "    reduction = extra_reducer * (driver_levels_2023 / driver_levels_2013)\n",
    "    \n",
    "\n",
    "    # apply scaling\n",
    "    print(\"Applying 2013 to 2023 scaling\")\n",
    "    \n",
    "    shift_counts_df = shift_counts_df.map(lambda arr: np.rint(arr * reduction).astype(np.int16))\n",
    "    driver_count_df = driver_count_df.map(lambda arr: np.rint(arr * reduction).astype(np.int16))\n",
    "\n",
    "    \n",
    "    # calculate mean and std for z-score adjustments\n",
    "    driver_count_means = driver_count_df.map(np.mean)\n",
    "    driver_count_stds = driver_count_df.map(np.std)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # GENERATION SECTION\n",
    "\n",
    "\n",
    "\n",
    "    # start a couple days before 2023\n",
    "    start_time = pd.Timestamp('2022-12-20')\n",
    "    adjustment_start = start_time + pd.Timedelta(days=5)\n",
    "    \n",
    "    # z_scores to add to remove shifts at\n",
    "    low_z_threshold = -3\n",
    "    high_z_threshold = 3\n",
    "    \n",
    "    \n",
    "    # end a couple days after 2023\n",
    "    timestamp_end = pd.Timestamp('2024-01-02')\n",
    "    #timestamp_end = pd.Timestamp('2023-01-02')\n",
    "    \n",
    "    shifts_dataframe = pd.DataFrame(columns=['start_time', 'start_locationID', 'duration', 'end_time'])\n",
    "    \n",
    "    \n",
    "    z_scores_list = []\n",
    "    z_adjustment_messages = []\n",
    "    \n",
    "    hours = pd.date_range(start=start_time, end=timestamp_end, freq=\"h\")\n",
    "    n = len(hours)\n",
    "    \n",
    "    \n",
    "    # make this long enough for max duration you might see (pick a safe buffer)\n",
    "    end_counts = np.zeros(n + 72*2, dtype=np.int32)  # e.g. +144 hours buffer\n",
    "    current_active = 0\n",
    "    \n",
    "    chunks = []\n",
    "    meta = []\n",
    "    \n",
    "    for t_idx, curr_time in tqdm(enumerate(hours), total=len(hours)):\n",
    "    \n",
    "        current_active -= end_counts[t_idx]\n",
    "    \n",
    "        # get hour and day of week for current time\n",
    "        hour = curr_time.hour\n",
    "        dow  = curr_time.day_of_week\n",
    "    \n",
    "        # sample the number of shifts to generate\n",
    "        num_starts = np.random.choice(shift_counts_df[dow][hour])\n",
    "    \n",
    "        # sample data arrays for these shifts\n",
    "        new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=num_starts)\n",
    "        new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=num_starts)\n",
    "    \n",
    "        # create new shifts\n",
    "        new_shifts = []\n",
    "        new_end_buckets = []\n",
    "        for i in range(num_starts):\n",
    "            # sample a new shift\n",
    "            # I'm just going to start shifts on the hour\n",
    "            new_shift_location_ID = new_location_IDs[i]\n",
    "            new_shift_duration = new_durations[i]\n",
    "            new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "    \n",
    "            end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "            end_counts[end_bucket] += 1\n",
    "            new_end_buckets.append(end_bucket)\n",
    "    \n",
    "            new_shifts.append({\n",
    "                'start_time' : curr_time,\n",
    "                'start_locationID' : new_shift_location_ID,\n",
    "                'duration' : new_shift_duration,\n",
    "                'end_time' : new_shift_end\n",
    "            })\n",
    "    \n",
    "        # create new shift dataframe\n",
    "        new_shift_df = pd.DataFrame(new_shifts)\n",
    "    \n",
    "        \n",
    "        current_active += num_starts\n",
    "    \n",
    "        chunks.append(new_shift_df)\n",
    "        meta.append(np.array(new_end_buckets))    \n",
    "\n",
    "        # since extreme outliers have been filtered with IQR, I'm going to\n",
    "        # use standard z-score for outlier detection for generation driver counts\n",
    "        obs_mean = driver_count_means[dow][hour]\n",
    "        obs_std  = driver_count_stds[dow][hour]\n",
    "        z_score = (current_active - obs_mean) / obs_std\n",
    "    \n",
    "        if z_score > high_z_threshold and curr_time > adjustment_start: # there's too many drivers\n",
    "    \n",
    "            # remove drivers to bring back into range\n",
    "            desired_amount = obs_mean + high_z_threshold * obs_std\n",
    "    \n",
    "            amount_to_remove = int(current_active - desired_amount)\n",
    "    \n",
    "            log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to remove: {amount_to_remove}\"\n",
    "            #print(log_message)\n",
    "            z_adjustment_messages.append(log_message)\n",
    "\n",
    "            # remove rows from previous chunks and current_active count\n",
    "            k = amount_to_remove\n",
    "            while k > 0 and chunks:\n",
    "                last_df = chunks[-1]\n",
    "                last_buckets = meta[-1]\n",
    "                take = min(k, len(last_df))\n",
    "    \n",
    "                # undo those shifts in the end_counts + active count\n",
    "                np.add.at(end_counts, last_buckets[-take:], -1)\n",
    "                current_active -= take\n",
    "    \n",
    "                # trim/pop chunk\n",
    "                if take == len(last_df):\n",
    "                    chunks.pop(); meta.pop()\n",
    "                else:\n",
    "                    chunks[-1] = last_df.iloc[:-take]\n",
    "                    meta[-1] = last_buckets[:-take]\n",
    "                k -= take\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "        if z_score < low_z_threshold and curr_time > adjustment_start: # theres too little drivers\n",
    "    \n",
    "            # remove drivers to bring back into range\n",
    "            desired_amount = obs_mean + low_z_threshold * obs_std\n",
    "    \n",
    "            amount_to_add = int(desired_amount - current_active)\n",
    "    \n",
    "            log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to add: {amount_to_add}\"\n",
    "            #print(log_message)\n",
    "            z_adjustment_messages.append(log_message)\n",
    "    \n",
    "            \n",
    "            # create that many drivers\n",
    "            new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=amount_to_add)\n",
    "            new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=amount_to_add)\n",
    "    \n",
    "            # create new shifts\n",
    "            new_shifts = []\n",
    "            new_end_buckets = []\n",
    "            for i in range(amount_to_add):\n",
    "                # sample a new shift\n",
    "                # I'm just going to start shifts on the hour\n",
    "                new_shift_location_ID = new_location_IDs[i]\n",
    "                new_shift_duration = new_durations[i]\n",
    "                new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "        \n",
    "                end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "                end_counts[end_bucket] += 1\n",
    "                new_end_buckets.append(end_bucket)\n",
    "        \n",
    "                new_shifts.append({\n",
    "                    'start_time' : curr_time,\n",
    "                    'start_locationID' : new_shift_location_ID,\n",
    "                    'duration' : new_shift_duration,\n",
    "                    'end_time' : new_shift_end\n",
    "                })\n",
    "        \n",
    "            # create new shift dataframe\n",
    "            new_shift_df = pd.DataFrame(new_shifts)\n",
    "        \n",
    "            \n",
    "            current_active += amount_to_add\n",
    "        \n",
    "            chunks[-1] = pd.concat([chunks[-1], new_shift_df], ignore_index=True)\n",
    "            meta[-1] = np.concat((meta[-1], np.array(new_end_buckets)))\n",
    "    \n",
    "    \n",
    "        z_scores_list.append(z_score)\n",
    "\n",
    "\n",
    "    print(\"Creating dataframe:...\")\n",
    "    z_scores = np.array(z_scores_list)\n",
    "    shift_dataframe = pd.concat(chunks)\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "    # return dataframe and z_scores. Filtering is done in other loop\n",
    "    return shift_dataframe, z_scores\n",
    "    \n",
    "\n",
    "\n",
    "def create_test_shift_information(test_folder, make_folder):\n",
    "\n",
    "    # Directory *where this script is located*\n",
    "    #script_dir = Path(__file__).resolve().parent\n",
    "    # Treat the argument as relative to the script dir\n",
    "    test_folder = Path(test_folder)\n",
    "\n",
    "    #print(test_folder)\n",
    "\n",
    "\n",
    "    if make_folder:\n",
    "        # check that the test folder does not exist\n",
    "        if test_folder.is_dir():\n",
    "            raise FileNotFoundError(f\"Test folder {test_folder} exists while make_folder is True!\")\n",
    "\n",
    "        os.mkdir(test_folder)\n",
    "\n",
    "    else:\n",
    "        # check that test folder exists\n",
    "        if not test_folder.is_dir():\n",
    "            raise FileNotFoundError(f\"Test folder {test_folder} doesn't exist!\")\n",
    "\n",
    "    # make export files\n",
    "    shift_dataframe_export_path  = test_folder / \"shift_information.parquet\"\n",
    "    z_scores_plot_export         = test_folder / \"zscores_plot.jpg\"\n",
    "    z_scores_numpy_export        = test_folder / \"below_thresholds.npy\"\n",
    "\n",
    "    \n",
    "    \n",
    "    # generate z_scores and shift dataframe\n",
    "    shift_dataframe, z_scores = generate_shifts_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "    # format and clean shift dataframe to save\n",
    "    \n",
    "\n",
    "    # slice out anything that starts in 2024\n",
    "    sliced_shifts = shift_dataframe[shift_dataframe['start_time'] < pd.Timestamp('2024-01-01')]\n",
    "    \n",
    "    # slice out anything that ends before 2023\n",
    "    sliced_shifts = sliced_shifts[sliced_shifts['end_time'] >= pd.Timestamp('2023-01-01')]\n",
    "    \n",
    "    # clamp start times to begging of 2023 and recalculate duration based on end_time\n",
    "    cutoff = pd.Timestamp('2023-01-01 00:00:00')\n",
    "    mask = sliced_shifts['start_time'] < cutoff\n",
    "    \n",
    "    # Update duration for affected rows (in hours)\n",
    "    sliced_shifts.loc[mask, 'duration'] = (\n",
    "        sliced_shifts.loc[mask, 'end_time'] - cutoff\n",
    "    ).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Clamp start_time to cutoff\n",
    "    sliced_shifts.loc[mask, 'start_time'] = cutoff\n",
    "\n",
    "\n",
    "    # set location ID column to int16\n",
    "    sliced_shifts['start_locationID'] = sliced_shifts['start_locationID'].astype(np.int16)\n",
    "    # remove end_time (not required for simulation)\n",
    "    export_shifts = sliced_shifts.drop(columns=['end_time'])\n",
    "\n",
    "    export_shifts.to_parquet(shift_dataframe_export_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # slice out beginning z_scores, make plot and save\n",
    "    z_scores = z_scores[24*5:]\n",
    "\n",
    "    low_z_threshold = -3\n",
    "    high_z_threshold = 3\n",
    "    out_of_threshold = ((z_scores < low_z_threshold) | (z_scores > high_z_threshold)).mean() * 100\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.plot(z_scores)\n",
    "    plt.title(f\"driver_count z_score plot, {out_of_threshold}% out of threshold\")\n",
    "    plt.xlabel(\"hour index\")\n",
    "    plt.ylabel(\"active_driver_count_z_score\")\n",
    "\n",
    "    plt.savefig(z_scores_plot_export, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    np.save(z_scores_numpy_export, z_scores)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c3f457-b37e-4f4f-95bd-df13fdd51023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# for loop to create test folders with shift information\n",
    "\n",
    "base_folder = \"test_v5/\"\n",
    "\n",
    "test_folders = [f\"test_{i}\" for i in range(8)]\n",
    "\n",
    "\n",
    "for test_folder in test_folders:\n",
    "\n",
    "\n",
    "    print(\"Test_folder:\", test_folder)\n",
    "\n",
    "    test_folder = base_folder + \"/\" + test_folder\n",
    "\n",
    "    \n",
    "    create_test_shift_information(test_folder, make_folder=True)\n",
    "\n",
    "\n",
    "    clear_output(wait=False)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d86086-2d67-4ddc-ad2d-6ce11e196dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90348b4-fe71-4c0d-bddd-aff6449ac420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c9620-aeef-4c41-8011-994de51f64e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b141893-8c43-43b0-914a-9712905c1f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79178651-4e45-42ec-8048-493c38c5192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31efaf-a1e8-406d-87b2-d3efb4a997f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e81a8-5220-467a-bb26-2a6e8326da85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edaf523-7ef3-4a76-a873-5c729163a874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424739a5-bc4e-4ea5-81f9-537116b014ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bf790-f08b-407b-92af-896f180c3373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76089a5-b108-48a5-90a7-2852b4c88c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7687a-2055-4d18-af13-e7ef30b47622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e76ac-4758-47ad-89fe-3c17d7568dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f508731-af00-4f10-9d4e-23af3ceb0dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85858407-107b-4455-8385-46785ff1baf2",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "\n",
    "# Generate shift information for ground truth 2013 simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd022ff-4813-4487-a9d1-2886e7065dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fafcbde-c23a-46ca-b7bd-615356b50db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(arr, k=3.0):\n",
    "    \"\"\"\n",
    "    Remove extreme outliers from a 1D numpy array using the IQR rule.\n",
    "    Returns a new array with only non-outlier values.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return arr  # keep empty arrays as-is\n",
    "\n",
    "    # Use percentiles for robustness\n",
    "    q1, q3 = np.percentile(arr, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0:\n",
    "        # All values nearly identical; nothing to remove\n",
    "        return arr\n",
    "\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "\n",
    "    mask = (arr >= lower) & (arr <= upper)\n",
    "\n",
    "    removed = arr[~mask]\n",
    "    if len(removed) > 0:\n",
    "        #print(\"Removed:\", removed)\n",
    "        #print(\"Kepted:\", arr[mask])\n",
    "        #print(\"\\n\\n\")\n",
    "        pass\n",
    "    return arr[mask]\n",
    "\n",
    "\n",
    "def generate_ground_truth_shifts_dataframe():\n",
    "\n",
    "    # load data\n",
    "    print(\"Shift start counts...\")\n",
    "    shift_counts_df = pd.read_pickle(\"data/sim_info/shift_start_counts_arrays.pkl\")\n",
    "    \n",
    "    print(\"Shift durations...\")\n",
    "    shift_durations_df = pd.read_pickle(\"data/sim_info/shift_arrays.pkl\")\n",
    "    \n",
    "    print(\"Shift start locations...\")\n",
    "    shift_start_locationsIDs_df = pd.read_pickle(\"data/sim_info/shift_start_location_arrays.pkl\")\n",
    "    \n",
    "    print(\"driver counts...\")\n",
    "    driver_count_df = pd.read_pickle(\"data/sim_info/driver_count_arrays.pkl\")\n",
    "\n",
    "\n",
    "    # filter extreme outliers in count dataframes\n",
    "    shift_counts_df = shift_counts_df.map(remove_outliers_iqr)\n",
    "    driver_count_df = driver_count_df.map(remove_outliers_iqr)\n",
    "\n",
    "\n",
    "    # calculate mean and std for z-score adjustments\n",
    "    driver_count_means = driver_count_df.map(np.mean)\n",
    "    driver_count_stds = driver_count_df.map(np.std)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # GENERATION SECTION\n",
    "\n",
    "\n",
    "\n",
    "    # start a couple days before 2013\n",
    "    start_time = pd.Timestamp('2012-12-20')\n",
    "    adjustment_start = start_time + pd.Timedelta(days=5)\n",
    "    \n",
    "    # z_scores to add to remove shifts at\n",
    "    low_z_threshold = -3\n",
    "    high_z_threshold = 3\n",
    "    \n",
    "    \n",
    "    # end a couple days after 2013\n",
    "    timestamp_end = pd.Timestamp('2014-01-02')\n",
    "    #timestamp_end = pd.Timestamp('2013-01-02')\n",
    "    \n",
    "    shifts_dataframe = pd.DataFrame(columns=['start_time', 'start_locationID', 'duration', 'end_time'])\n",
    "    \n",
    "    \n",
    "    z_scores_list = []\n",
    "    z_adjustment_messages = []\n",
    "    \n",
    "    hours = pd.date_range(start=start_time, end=timestamp_end, freq=\"h\")\n",
    "    n = len(hours)\n",
    "    \n",
    "    \n",
    "    # make this long enough for max duration you might see (pick a safe buffer)\n",
    "    end_counts = np.zeros(n + 72*2, dtype=np.int32)  # e.g. +144 hours buffer\n",
    "    current_active = 0\n",
    "    \n",
    "    chunks = []\n",
    "    meta = []\n",
    "    \n",
    "    for t_idx, curr_time in tqdm(enumerate(hours), total=len(hours)):\n",
    "    \n",
    "        current_active -= end_counts[t_idx]\n",
    "    \n",
    "        # get hour and day of week for current time\n",
    "        hour = curr_time.hour\n",
    "        dow  = curr_time.day_of_week\n",
    "    \n",
    "        # sample the number of shifts to generate\n",
    "        num_starts = np.random.choice(shift_counts_df[dow][hour])\n",
    "    \n",
    "        # sample data arrays for these shifts\n",
    "        new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=num_starts)\n",
    "        new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=num_starts)\n",
    "    \n",
    "        # create new shifts\n",
    "        new_shifts = []\n",
    "        new_end_buckets = []\n",
    "        for i in range(num_starts):\n",
    "            # sample a new shift\n",
    "            # I'm just going to start shifts on the hour\n",
    "            new_shift_location_ID = new_location_IDs[i]\n",
    "            new_shift_duration = new_durations[i]\n",
    "            new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "    \n",
    "            end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "            end_counts[end_bucket] += 1\n",
    "            new_end_buckets.append(end_bucket)\n",
    "    \n",
    "            new_shifts.append({\n",
    "                'start_time' : curr_time,\n",
    "                'start_locationID' : new_shift_location_ID,\n",
    "                'duration' : new_shift_duration,\n",
    "                'end_time' : new_shift_end\n",
    "            })\n",
    "    \n",
    "        # create new shift dataframe\n",
    "        new_shift_df = pd.DataFrame(new_shifts)\n",
    "    \n",
    "        \n",
    "        current_active += num_starts\n",
    "    \n",
    "        chunks.append(new_shift_df)\n",
    "        meta.append(np.array(new_end_buckets))    \n",
    "\n",
    "        # since extreme outliers have been filtered with IQR, I'm going to\n",
    "        # use standard z-score for outlier detection for generation driver counts\n",
    "        obs_mean = driver_count_means[dow][hour]\n",
    "        obs_std  = driver_count_stds[dow][hour]\n",
    "        z_score = (current_active - obs_mean) / obs_std\n",
    "    \n",
    "        if z_score > high_z_threshold and curr_time > adjustment_start: # there's too many drivers\n",
    "    \n",
    "            # remove drivers to bring back into range\n",
    "            desired_amount = obs_mean + high_z_threshold * obs_std\n",
    "    \n",
    "            amount_to_remove = int(current_active - desired_amount)\n",
    "    \n",
    "            log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to remove: {amount_to_remove}\"\n",
    "            #print(log_message)\n",
    "            z_adjustment_messages.append(log_message)\n",
    "\n",
    "            # remove rows from previous chunks and current_active count\n",
    "            k = amount_to_remove\n",
    "            while k > 0 and chunks:\n",
    "                last_df = chunks[-1]\n",
    "                last_buckets = meta[-1]\n",
    "                take = min(k, len(last_df))\n",
    "    \n",
    "                # undo those shifts in the end_counts + active count\n",
    "                np.add.at(end_counts, last_buckets[-take:], -1)\n",
    "                current_active -= take\n",
    "    \n",
    "                # trim/pop chunk\n",
    "                if take == len(last_df):\n",
    "                    chunks.pop(); meta.pop()\n",
    "                else:\n",
    "                    chunks[-1] = last_df.iloc[:-take]\n",
    "                    meta[-1] = last_buckets[:-take]\n",
    "                k -= take\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "        if z_score < low_z_threshold and curr_time > adjustment_start: # theres too little drivers\n",
    "    \n",
    "            # remove drivers to bring back into range\n",
    "            desired_amount = obs_mean + low_z_threshold * obs_std\n",
    "    \n",
    "            amount_to_add = int(desired_amount - current_active)\n",
    "    \n",
    "            log_message = f\"{curr_time.strftime('%Y-%m-%d')}   dow: {dow},  hour: {hour},   current: {current_active}, amount to add: {amount_to_add}\"\n",
    "            #print(log_message)\n",
    "            z_adjustment_messages.append(log_message)\n",
    "    \n",
    "            \n",
    "            # create that many drivers\n",
    "            new_location_IDs = np.random.choice(shift_start_locationsIDs_df[dow][hour], replace=True, size=amount_to_add)\n",
    "            new_durations    = np.random.choice(shift_durations_df[dow][hour], replace=True, size=amount_to_add)\n",
    "    \n",
    "            # create new shifts\n",
    "            new_shifts = []\n",
    "            new_end_buckets = []\n",
    "            for i in range(amount_to_add):\n",
    "                # sample a new shift\n",
    "                # I'm just going to start shifts on the hour\n",
    "                new_shift_location_ID = new_location_IDs[i]\n",
    "                new_shift_duration = new_durations[i]\n",
    "                new_shift_end = curr_time + pd.Timedelta(hours=new_shift_duration)\n",
    "        \n",
    "                end_bucket = t_idx + np.ceil(new_shift_duration).astype(np.int32)\n",
    "                end_counts[end_bucket] += 1\n",
    "                new_end_buckets.append(end_bucket)\n",
    "        \n",
    "                new_shifts.append({\n",
    "                    'start_time' : curr_time,\n",
    "                    'start_locationID' : new_shift_location_ID,\n",
    "                    'duration' : new_shift_duration,\n",
    "                    'end_time' : new_shift_end\n",
    "                })\n",
    "        \n",
    "            # create new shift dataframe\n",
    "            new_shift_df = pd.DataFrame(new_shifts)\n",
    "        \n",
    "            \n",
    "            current_active += amount_to_add\n",
    "        \n",
    "            chunks[-1] = pd.concat([chunks[-1], new_shift_df], ignore_index=True)\n",
    "            meta[-1] = np.concat((meta[-1], np.array(new_end_buckets)))\n",
    "    \n",
    "    \n",
    "        z_scores_list.append(z_score)\n",
    "\n",
    "\n",
    "    print(\"Creating dataframe:...\")\n",
    "    z_scores = np.array(z_scores_list)\n",
    "    shift_dataframe = pd.concat(chunks)\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "    # return dataframe and z_scores. Filtering is done in other loop\n",
    "    return shift_dataframe, z_scores\n",
    "    \n",
    "\n",
    "\n",
    "def create_ground_truth_test_shift_information(test_folder, make_folder):\n",
    "\n",
    "    # Directory *where this script is located*\n",
    "    #script_dir = Path(__file__).resolve().parent\n",
    "    # Treat the argument as relative to the script dir\n",
    "    test_folder = Path(test_folder)\n",
    "\n",
    "    #print(test_folder)\n",
    "\n",
    "\n",
    "    if make_folder:\n",
    "        # check that the test folder does not exist\n",
    "        if test_folder.is_dir():\n",
    "            raise FileNotFoundError(f\"Test folder {test_folder} exists while make_folder is True!\")\n",
    "\n",
    "        os.mkdir(test_folder)\n",
    "\n",
    "    else:\n",
    "        # check that test folder exists\n",
    "        if not test_folder.is_dir():\n",
    "            raise FileNotFoundError(f\"Test folder {test_folder} doesn't exist!\")\n",
    "\n",
    "    # make export files\n",
    "    shift_dataframe_export_path  = test_folder / \"shift_information.parquet\"\n",
    "    z_scores_plot_export         = test_folder / \"zscores_plot.jpg\"\n",
    "    z_scores_numpy_export        = test_folder / \"below_thresholds.parquet\"\n",
    "\n",
    "    \n",
    "    \n",
    "    # generate z_scores and shift dataframe\n",
    "    shift_dataframe, z_scores = generate_ground_truth_shifts_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "    # format and clean shift dataframe to save\n",
    "    \n",
    "\n",
    "    # slice out anything that starts in 2014\n",
    "    sliced_shifts = shift_dataframe[shift_dataframe['start_time'] < pd.Timestamp('2014-01-01')]\n",
    "    \n",
    "    # slice out anything that ends before 2013\n",
    "    sliced_shifts = sliced_shifts[sliced_shifts['end_time'] >= pd.Timestamp('2013-01-01')]\n",
    "    \n",
    "    # clamp start times to begging of 2013 and recalculate duration based on end_time\n",
    "    cutoff = pd.Timestamp('2013-01-01 00:00:00')\n",
    "    mask = sliced_shifts['start_time'] < cutoff\n",
    "    \n",
    "    # Update duration for affected rows (in hours)\n",
    "    sliced_shifts.loc[mask, 'duration'] = (\n",
    "        sliced_shifts.loc[mask, 'end_time'] - cutoff\n",
    "    ).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Clamp start_time to cutoff\n",
    "    sliced_shifts.loc[mask, 'start_time'] = cutoff\n",
    "\n",
    "\n",
    "    # set location ID column to int16\n",
    "    sliced_shifts['start_locationID'] = sliced_shifts['start_locationID'].astype(np.int16)\n",
    "    # remove end_time (not required for simulation)\n",
    "    export_shifts = sliced_shifts.drop(columns=['end_time'])\n",
    "\n",
    "    export_shifts.to_parquet(shift_dataframe_export_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # slice out beginning z_scores, make plot and save\n",
    "    z_scores = z_scores[24*5:]\n",
    "\n",
    "    low_z_threshold = -3\n",
    "    high_z_threshold = 3\n",
    "    out_of_threshold = ((z_scores < low_z_threshold) | (z_scores > high_z_threshold)).mean() * 100\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.plot(z_scores)\n",
    "    plt.title(f\"driver_count z_score plot, {out_of_threshold}% out of threshold\")\n",
    "    plt.xlabel(\"hour index\")\n",
    "    plt.ylabel(\"active_driver_count_z_score\")\n",
    "\n",
    "    plt.savefig(z_scores_plot_export, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    np.save(z_scores_numpy_export, z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163a2a97-fc02-4c12-8c2a-0af1e412cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# for loop to create test folders with shift information\n",
    "\n",
    "base_folder = \"gt_sims_v1\"\n",
    "\n",
    "test_folders = [f\"test_{i}\" for i in range(8)]\n",
    "\n",
    "test_folders = [\"test_0\"]\n",
    "\n",
    "for test_folder in test_folders:\n",
    "\n",
    "\n",
    "    print(\"Test_folder:\", test_folder)\n",
    "\n",
    "    test_folder = base_folder + \"/\" + test_folder\n",
    "\n",
    "    \n",
    "    create_ground_truth_test_shift_information(test_folder, make_folder=True)\n",
    "\n",
    "\n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281c4a4-1a47-4586-9aa1-49da7c76284f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d69ebf5-84d5-4f84-be4a-a430a46d3c78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$ $$\n",
    "\n",
    "# Update simulation to be numpy and numba based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e4b166-efef-47b8-a8ba-46d57fdca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2313ed-2c9b-4990-b774-f47e9530a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gt_simulation_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db042b0d-60ee-4253-9eee-ef70a89f2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gt_simulation_v4 import check_series_is_full, convert_array_df, fill_df_missing_cols_rows, get_PU_to_DO_connections, load_sampling_stuff\n",
    "from gt_simulation_v4 import TaxiFleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5b8589-77a7-4edb-a096-5883e4bcb022",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e601d6-ef12-4b19-8ee9-76b79a94fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_arg = 'gt_sims_v1/test_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5056d014-6e7a-4904-8e71-3bb15162581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sampling info:\n",
      "Shift durations...\n",
      "Shift start locations...\n",
      "driver counts...\n",
      "driver count deltas...\n",
      "In between miles...\n",
      "Filling in missing columns and rows with empty arrays\n",
      "missing cols: {104, 57, 105}\n",
      "missing rows: {104, 57, 105}\n",
      "In between durations...\n",
      "Filling in missing columns and rows with empty arrays\n",
      "missing cols: {104, 57, 105}\n",
      "missing rows: {104, 57, 105}\n",
      "Converting measurements\n",
      "Simulation cutoff: 2013-01-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Directory *where this script is located*\n",
    "#script_dir = Path(__file__).resolve().parent\n",
    "# Treat the argument as relative to the script dir\n",
    "#test_folder = (script_dir / test_folder_arg).resolve()\n",
    "test_folder = Path(test_folder_arg)\n",
    "\n",
    "if not test_folder.is_dir():\n",
    "    raise FileNotFoundError(f\"Test folder {test_folder} doesn't exist!\")\n",
    "\n",
    "# check paths special to test (should just be trip and config)\n",
    "shift_df_path = test_folder / \"shift_information.parquet\"\n",
    "test_config_path = test_folder / \"test_config.yaml\"\n",
    "\n",
    "if not shift_df_path.exists():\n",
    "    raise FileNotFoundError(f\"Shift file {shift_df_path} doesn't exist within test folder!\")\n",
    "if not test_config_path.exists():\n",
    "    raise FileNotFoundError(f\"Config file {test_config_path} doesn't exist within test folder!\")\n",
    "\n",
    "\n",
    "# Create paths for exports\n",
    "sim_time_export              = test_folder / \"gen_info.txt\"\n",
    "rejects_export_path          = test_folder / \"rejects.parquet\"\n",
    "below_thresholds_export_path = test_folder / \"below_thresholds.parquet\"\n",
    "unfilled_trips_export_path   = test_folder / \"unfilled_trips.parquet\"\n",
    "\n",
    "\n",
    "# read test config file\n",
    "with open(test_config_path,'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load sampling distributions\n",
    "sampling_stuff = load_sampling_stuff()\n",
    "\n",
    "# load information for DO to PU connections (filtered by occurance minimum threshold, default is 365)\n",
    "PU_to_DO_info = get_PU_to_DO_connections(threshold=config_dict['connections_threshold'])\n",
    "\n",
    "\n",
    "# load in raw trips\n",
    "unformatted_trips = pd.read_parquet(\"data/sim_info/ground_truth_trips_raw.parquet\")\n",
    "unformatted_trips = unformatted_trips.sort_values(by=\"PU_time\")\n",
    "\n",
    "\n",
    "# Convert trip times into seconds since start of 2013\n",
    "t0 = pd.Timestamp(\"2013-01-01 00:00:00\")\n",
    "\n",
    "trips = unformatted_trips.copy()\n",
    "\n",
    "\n",
    "# if there's a set simulation cutoff, then slice trips dataframe\n",
    "if config_dict['end_date']:\n",
    "    end_date = pd.Timestamp(config_dict['end_date'])\n",
    "    print(\"Simulation cutoff:\", end_date)\n",
    "\n",
    "    trips = trips[trips['PU_time'] <= end_date]\n",
    "\n",
    "\n",
    "# Seconds since start of 2013\n",
    "trips['PU'] = (trips['PU_time'] - t0).dt.total_seconds().astype('int')\n",
    "trips['DO'] = (trips['DO_time'] - t0).dt.total_seconds().astype('int')\n",
    "trips.drop(columns=['PU_time', 'DO_time'], inplace=True)\n",
    "\n",
    "# create duration column in seconds and then drop dropoff time\n",
    "trips['duration'] = trips['DO'] - trips['PU']\n",
    "trips.drop(columns=['DO'], inplace=True)\n",
    "trips = trips.sort_values(by='PU')\n",
    "\n",
    "# reset trips index (used for flag to clean taxi cab array)\n",
    "trips = trips.reset_index()\n",
    "trips.drop(columns=['index'], inplace=True)\n",
    "\n",
    "\n",
    "# load in test trip df\n",
    "shift_df = pd.read_parquet(shift_df_path)\n",
    "\n",
    "# convert start time to seconds from start of 2013\n",
    "shift_df['start_time'] = (shift_df['start_time']  - t0).dt.total_seconds().astype('int')\n",
    "# convert duration to seconds (is currently hours)\n",
    "shift_df['duration'] = (shift_df['duration'] * 3600).round().astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6745fe-9fe1-48b8-85ea-c3a8d04e10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3785874/3785874 [00:49<00:00, 76217.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# create fleet with loaded data and config settings\n",
    "fleet = TaxiFleet(\n",
    "    taxi_shifts_df=shift_df, \n",
    "    taxi_range= config_dict['taxi_range'], \n",
    "    trips_df=trips, \n",
    "    sampling_stuff=sampling_stuff, \n",
    "    PU_to_DO_info=PU_to_DO_info,\n",
    "    low_range_threshold=config_dict['low_range_threshold']\n",
    ")\n",
    "\n",
    "cleaning_time = 0\n",
    "\n",
    "# run through all trips\n",
    "start = time.time()\n",
    "\n",
    "cab_array_cleaning_interval = config_dict['cab_array_cleaning_interval']\n",
    "\n",
    "backlog_waiting_seconds = config_dict['backlog_waiting_minutes'] * 60\n",
    "\n",
    "takens = []\n",
    "b_trip_takens = []\n",
    "\n",
    "backlogged_trips = []\n",
    "\n",
    "back_filled_trips = []\n",
    "unfilled_trips = []\n",
    "\n",
    "for row in tqdm(trips.itertuples(index=True), total=len(trips)):\n",
    "\n",
    "    # back log eval loop\n",
    "    while len(backlogged_trips) > 0:\n",
    "\n",
    "        if backlogged_trips[0].PU < row.PU + backlog_waiting_seconds:  # the backlogged trip has waited at least the waiting period\n",
    "            b_trip = backlogged_trips.pop(0)\n",
    "\n",
    "            # run b_trip through backlog try function\n",
    "            b_trip_taken = fleet.assign_trip(pickup_time_seconds = b_trip.PU + backlog_waiting_seconds, \n",
    "                                             pickup_location     = b_trip.PU_LocationID, \n",
    "                                             duration            = b_trip.duration, \n",
    "                                             distance            = b_trip.distance, \n",
    "                                             dropoff_location    = b_trip.DO_LocationID\n",
    "                                            )\n",
    "\n",
    "            if b_trip_taken:\n",
    "                # add to back_filled_trips\n",
    "                back_filled_trips.append(b_trip)\n",
    "                \n",
    "            else:\n",
    "                # add to unfilled trips\n",
    "                unfilled_trips.append(b_trip)\n",
    "\n",
    "            b_trip_takens.append(b_trip_taken)\n",
    "\n",
    "        else:\n",
    "            # latest backlog hasn't waited long enough.\n",
    "            # So break out to continue normal trips to backlog has waited enough\n",
    "            break\n",
    "    \n",
    "    \n",
    "    taken = fleet.assign_trip(\n",
    "        pickup_time_seconds = row.PU, \n",
    "        pickup_location     = row.PU_LocationID, \n",
    "        duration            = row.duration, \n",
    "        distance            = row.distance, \n",
    "        dropoff_location    = row.DO_LocationID\n",
    "    )\n",
    "\n",
    "    takens.append(taken)\n",
    "\n",
    "    if row.Index % 5_000 == 0 and row.Index > 100:\n",
    "        #before_size = np.array([len(taxi_array) for taxi_array in fleet.cab_array]).sum()\n",
    "        #print(\"before_size:\", fleet.next_location_taxi_index)\n",
    "        clean_start = time.time()\n",
    "        fleet.clean_cab_array(curr_time_seconds=row.PU - backlog_waiting_seconds)\n",
    "        cleaning_time += time.time() - clean_start\n",
    "        #after_size = np.array([len(taxi_array) for taxi_array in fleet.cab_array]).sum()\n",
    "        #print(\"after_size:\", after_size)\n",
    "        #print(\"before_size:\", fleet.next_location_taxi_index)\n",
    "        #print(np.sum(fleet.next_location_taxi_index))\n",
    "        #break\n",
    "\n",
    "    if not taken:\n",
    "        backlogged_trips.append(row)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79bdb3be-f416-4b46-b026-69a3ec149e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_trip_processing_time: 38.82381200790405\n",
      "search_primary_time: 8.320680379867554\n",
      "search_secondary_time: 12.55385136604309\n",
      "time_spawning 1.8021795749664307\n",
      "post_find_time 11.894316911697388\n",
      "\n",
      "primary searches: 2132108\n",
      "secondary searches: 1543252\n",
      "failed searches: 345132\n",
      "\n",
      "cleaning time: 0.2736949920654297\n"
     ]
    }
   ],
   "source": [
    "print(\"total_trip_processing_time:\", fleet.total_trip_processing_time)\n",
    "print(\"search_primary_time:\", fleet.search_primary_time)\n",
    "print(\"search_secondary_time:\", fleet.search_secondary_time)\n",
    "print(\"time_spawning\", fleet.time_spawning)\n",
    "print(\"post_find_time\", fleet.post_find_time)\n",
    "print()\n",
    "print(\"primary searches:\", fleet.search_primary_count)\n",
    "print(\"secondary searches:\", fleet.search_secondary_count)\n",
    "print(\"failed searches:\", fleet.search_fails)\n",
    "print()\n",
    "print(\"cleaning time:\", cleaning_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5834",
   "language": "python",
   "name": "cs5834"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
